– The prover sends a commitment x to the verifier;
– The verifier replies with a challenge c;
– The prover gives a response y.
Upon completion, V may accept or reject P, depending on whether P’s answer is
satisfactory. Such a description encompasses well-known identification protocols
such as Feige-Fiat-Shamir [10] and Girault-Poupard-Stern [11].
Formally, let R be some (polynomial-time) recognizable relation, then the
set L = {v s.t. ∃w, (v, w) ∈ R} defines a language. Proving that v ∈ L therefore
amounts to proving knowledge of a witness w such that (v, w) ∈ R. A Σ-protocol
satisfies the following three properties:
– Completeness: given an input v and a witness w such that (v, w) ∈ R, P is
always able to convince V.
Slow Motion Zero Knowledge Identifying with Colliding Commitments 383
– Special honest-verifier zero-knowledge1: there exists a probabilistic
polynomial-time simulator S which, given v and a c, outputs triples (x, c, y)
that have the same distribution as in a valid conversation between P and V.
– Special soundness: given two accepting conversations for the same input v,
with different challenges but an identical commitment x, there exists a prob-
abilistic polynomial-time extractor procedure E that computes a witness w
such that (v, w) ∈ R.
Many generalizations of zero-knowledge protocols have been discussed in the
literature. One critical question for instance is to compose such protocols in
parallel [14,18], or to use weaker indistinguishably notions (e.g., computational
indistinguishability).
2.2 Commitment Pre-processing
Because the commitment x does not depend on the challenge c, authors quickly
noted that x can be prepared in advance. This is of little use in protocols where
the creation of x is easy (e.g., Fiat-Shamir [10]). Discrete-logarithm commitment
pre-processing is a well-known optimization technique (e.g., [19,22]) that exploits
two properties of DLP:
1. In DLP-based protocols, a commitment is generated by computing the expo-
nentiation x = gr in a well-chosen group. This operation claims most of the
prover’s efforts.
2. The commitment x being unrelated to the challenge c, can hence be com-
puted in advance. A “pre-computed commitment” is hence defined as {r, x}
computed in advance by P2. Because several pre-computed commitments
usually need to be saved by P for later use, it is possible to derive all the ri
components by hashing a common seed.
Such pre-processing is interesting as it enables very fast interaction between
prover and verifier. While the technique described in this work does not require
the use of pre-processing, it is entirely compatible with such optimizations.
2.3 Time-Lock Puzzles
Time-lock puzzles [17,21] are problems designed to guarantee that they will take
(approximately) τ units of time to solve. Like proof-of-work protocols [8], time-
locks have found applications in settings where delaying requests is desirable,
such as fighting spam or denial-of-service attacks, as well as in electronic cash
[1,7,9].
Time-lock puzzles may be based on computationally demanding problems,
but not all such problems make good time-locks. For instance, inverting a weak
1 Note that special honest-verifier zero-knowledge implies honest-verifier zero-
knowledge.
2 Or for P by a trusted authority.
384 H. Ferradi et al.
one-way function would in general not provide a good time-lock candidate [21].
The intuition is that the time it takes to solve a time-lock should not be sig-
nificantly reduced by using more computers (i.e., parallel brute-force) or more
expensive machines.
A time-lock puzzle is informally described as a problem such that there is a
super-polynomial gap between the work required to generate the puzzle, and the
parallel time required to solve it (for a polynomial number of parallel processors).
The following definition formalizes this idea [5].
Definition 1 (Time-Lock Puzzle). A time-lock puzzle is the data two PPT
algorithms TG(1k, t) (problem generator) and TV (1k, a, v) (solution verifier) sat-
isfying the following properties:
– For every PPT algorithm B(1k, q, h), for all e ∈ N, there exists m ∈ N such
that
sup
t≥km,|h|≤ke
Pr
[
(q, a) ← TG(1k, t) s.t. TV (1k, a, B(1k, q, h)) = 1
]
is negl(k). Intuitively, TG generates puzzles of hardness t, and B cannot eff-
icently solve any puzzle of hardness t ≥ km for some constant m depending
on B.
– There is some m ∈ N such that, for every d ∈ N , there is a PPT algorithm
C(1k, t) such that
min
t≤kd
Pr
[
(q, a) ← TG(1k, t), v ← C(1k, q) s.t. TV (1k, a, v) = 1 and |v| ≤ km
]
is overwhelming in k. Intuitively, this second requirement ensures that for any
polynomial hardness value, there exists an algorithm that can solve any puzzle
of that hardness.
Rivest, Shamir and Wagner [21], and independently Boneh and Naor [4] proposed
a time-lock puzzle construction relying on the assumption that factorization is
hard. This is the construction we retain for this work, and to the best of our
knowledge the only known one to achieve interesting security levels. The orig-
inal Rivest-Shamir-Wagner (RSW) time-lock [21] is based on the “intrinsically
sequential” problem of computing:
22
τ
mod n
for specified values of τ and an RSA modulus n. The parameter τ controls the
puzzle’s difficulty. The puzzle can be solved by performing τ successive squares
modulo n.
Using the formalism above, the RSW puzzle can be described as follows:
TG(1k, t) =
(
(p1p2,min(t, 2k)), (p1, p2,min(t, 2k))
)
TV (1k, (p1, p2, t′), v) =
{
1 if (v = v1, v2) and v1 = 22
t′
mod n and v2 = n
0 otherwise
Slow Motion Zero Knowledge Identifying with Colliding Commitments 385
where p1 and p2 are (k/2)-bit prime numbers. Both solving the puzzle and ver-
ifying the solution can be efficiently done if p1 and p2 are known.
Good time-lock problems seem to be hard to find, and in particular there exist
impossibility results against unbounded adversaries [17]. Nevertheless, the RSW
construction holds under a computational assumption, namely that factorisation
of RSA moduli is hard.
3 Slow Motion Zero-Knowledge Protocols
3.1 Definition
We can now introduce the following notion:
Definition 2 (SM-ZK). A Slow Motion Zero-Knowledge (SM-ZK) protocol
(σ, T , τ,Δmax), where σ defines a Σ protocol, T is a time-lock puzzle, τ ∈ N,
and Δmax ∈ R, is defined by the three following steps of σ:
1. Commitment: P sends a commitment x to V
2. Timed challenge: V sends a challenge c to P, and starts a timer.
3. Response: P provides a response y to V, which stops the timer.
V accepts iif
– y is accepted as a satisfactory response by σ; and
– x is a solution to the time-lock puzzle T with input (y, c) and hardness τ ; and
– time elapsed between challenge and response, as measured by the timer, is
smaller than Δmax.
3.2 Commitment Shortening
Commitments in a Σ-protocol are under the control of P, which may be mali-
cious. If commitments are not collision-resistant, the protocol’s security is weak-
ened. Hence commitments need to be long, and in classical Σ protocols breaking
below the collision-resistance size barrier is impossible as proved by [13].
However, as we now show, commitment collision-resistance becomes unnec-
essary in the case of SM-ZK protocols.
4 An Example SM-ZK
While SM-ZK can be instantiated with any three-pass ZK protocol, we will
illustrate the construction using the Girault-Poupard-Stern (GPS) protocol [11,
12,20], and a modification of the time-lock construction due to Rivest, Shamir
and Wagner [21].
386 H. Ferradi et al.
Fig. 1. Girault-Poupard-Stern identification protocol.
4.1 Girault-Poupard-Stern Protocol
GPS key generation consists in generating a composite modulus n, choosing a
public generator g ∈ [0, n − 1] and integers A,B, S such that A  BS. Choice
of parameters depends on the application and is discussed in [12]. Implicitly,
parameters A,B, S are functions of the security parameter k.
The secret key is an integer s ∈ [0, S − 1], and the corresponding public key
is v = g−s mod n. Authentication is performed as in Fig. 1.
P can also precompute as many values xi ← gri as suitable for the applica-
tion, storing a copy of ri for later usage. The detailed procedure by which this
is done is recalled in AppendixB.
4.2 GPS-RSW SM-ZK
We can now combine the previous building-blocks to construct a pre-processing
scheme that requires little commitment storage.
The starting point is a slightly modified version of the RSW time-lock func-
tion τ 	→ 22τ . Let μ be some deterministic function (to be defined later) and n an
RSA modulus different from the n used for the GPS, we define for integers τ, :
fτ,(x) =
(
μ(x)2
τ
mod n
)
mod 2.
Here, τ controls the puzzle hardness and  is a parameter controlling output size.
The function fτ, only differs from the RSW time-lock in two respects: We
use μ(x) instead of 2; and the result is reduced modulo 2.
Slow Motion Zero Knowledge Identifying with Colliding Commitments 387
The motivation behind using a function μ stems from the following observa-
tion: An adversary knowing x2
τ
1 and x
2τ
2 could multiply them to get (x1x2)
2τ .
To thwart such attacks (and similar attacks based on the malleability of RSA)
we suggest to use for μ a deterministic RSA signature padding function (e.g.,
the Full Domain Hash [2]).
The reduction modulo 2 is of practical interest, it is meant to keep the
size of answers manageable. Of course, an adversary could brute-force all values
between 0 and 2 − 1 instead of trying to solve the time-lock. To avoid this
situation,  and τ should be chosen so that solving the time-lock is the most
viable option of the two.
Under the same assumptions as RSW (hardness of factorization), and if 
and τ are properly tuned, fτ, generates a time-lock problem.
Then, we adapt a construction of M’Räıhi and Naccache [19] to GPS [11].
This is done by defining a secret J , a public hash function H, and computing
the quantities:
x′i = g
H(J,i,s) mod n
This computation can be delegated to a trusted authority. This is interesting in
our case because the authority can compress these x′i by computing xi = fτ,(x
′
i).
Note that because the authority knows the factors of n, computing the xi is fast.
P is loaded with k pre-computed commitments x1, . . . , xk as shown in Fig. 2. The
quantity k of pre-computed commitments depends on the precise application.
Fig. 2. Slow motion commitment pre-processing for GPS.
When V wishes to authenticate P the parties execute the protocol shown in
Fig. 3.
With a proper choice of τ,  we can have a reasonable verification time (assum-
ing that V is more powerful than P), extremely short commitments (e.g., 40-bit
ones) and very little on-line computations required from P.
388 H. Ferradi et al.
Fig. 3. Slow Motion GPS. Range tests on c and y omitted for the sake of clarity.
4.3 Choice of Parameters
What drives the choice of parameters is the ratio between:
– The time t it takes to a legitimate prover to compute y and transmits it. In
GPS this is simply one multiplication of operands of sizes log2 B and log2 S
(additions neglected), this takes time λ log(B) log(S) for some constant λ (not
assuming optimizations such as [3] based on the fact that operand s is con-
stant).
– The time T it takes for the fastest adversary to evaluate once the time-lock
function fτ,. T does not really depend on , and is linear in τ . We hence let
T = ντ . Note that there is no need to take into account the size of n, all we
require from n is to be hard to factor. That way, the slowing effect will solely
depend on τ .
In a brute-force attack, there are 2 possibilities to exhaust. The most pow-
erful adversary may run κ ≤ 2 parallel evaluations of the time-lock function,
and succeed to solve the puzzle in t time units with probability

 =
κt
2T
=
κ log(B) log(S)λ
ν2τ
A typical instance resulting in 40-bit commitments is {κ = 224, T = 1, t =
2−4, 
 = 2−20} ⇒  = 40. Here we assume that the attacker has 16.7 million
(224) computers capable of solving one time-lock challenge per second (T = 1)
Slow Motion Zero Knowledge Identifying with Colliding Commitments 389
posing as a prover responding in one sixteenth of a second (t = 2−4). Assuming
the least secure DSA parameters (160-bit q) this divides commitment size by 4.
For 256-bit DSA the gain ratio becomes 6.4.
The time-out constant Δmax in Fig. 3 is tuned to be as small as possible, but
not so short that it prevents legitimate provers from authenticating. Therefore
the only constraint is that Δmax is greater or equal to the time t it takes to the
slowest legitimate prover to respond. Henceforth we assume Δmax = t.
5 Security Proof
The security of this protocol is related to that of the standard GPS protocol
analysed in [12,20]. We recall here the main results and hypotheses.
5.1 Preliminaries
The following scenario is considered. A randomized polynomial-time algorithm
Setup generates the public parameters (G, g, S) on input the security parameter
k. Then a second probabilistic algorithm GenKey generates pairs of public and
private keys, sends the secret key to P while the related public key is made
available to anybody, including of course P and V. Finally, the identification
procedure is a protocol between P and V, at the end of which V accepts or not.
An adversary who doesn’t corrupt public parameters and key generation
has only two ways to obtain information: either passively, by eavesdropping
on a regular communication, or actively, by impersonating (in a possibly non
protocol-compliant way) P and V.
The standard GPS protocol is proven complete, sound and zero-knowledge
by reduction to the discrete logarithm with short exponent problem [12]:
Definition 3 (Discrete Logarithm with Short Exponent Problem).
Given a group G, g ∈ G, and integer S and a group element gx such that
x ∈ [0, S − 1], find x.
5.2 Compressed Commitments for Time-Locked GPS
We now consider the impact of shortening the commitments to  bits on secu-
rity, while taking into account the time constraint under which P operates. The
shortening of commitments will indeed weaken the protocol [13] but this is com-
pensated by the time constraint, as explained below.
Lemma 1 (Completeness). Execution of the protocol of Fig. 3 between a
prover P who knows the secret key corresponding to his public key, and replies
in bounded time Δmax, and a verifier V is always successful.
Proof. This is a direct consequence of the completeness of the standard GPS
protocol [12, Theorem 1]. By assumption, P computes y and sends it within the
390 H. Ferradi et al.
time allotted for the operation. This computation is easy knowing the secret s
and we have
gyvc = gri+csvc = x′ig
csvc = x′iv
c−c = x′i
Consequently, fτ,(gyvc) = fτ,(x′i) = xi. Finally,
y = r + cs ≤ (A − 1) + (B − 1)(S − 1) < ymax.
Therefore all conditions are met and the identification succeeds. 
Lemma 2 (Zero-Knowledge). The protocol of Fig. 3 is statistically zero-
knowledge if it is run a polynomial number of times N , B is polynomial, and
NSB/A is negligible.
Proof. The proof follows [12] and can be found in AppendixA.
The last important property to prove is that if V accepts, then with over-
whelming probability P must know the discrete logarithm of v in base g.
Lemma 3 (Time-Constrained Soundness). Under the assumption that the
discrete logarithm with short exponent problem is hard, and the time-lock hard-
ness assumption, this protocol achieves time-constrained soundness.
Proof. After a commitment x has been sent, if A can correctly answer with
probability > 1/B then he must be able to answer to two different challenges,
c and c′, with y and y′ such that they are both accepted, i.e., fτ,(gyvc) = x =
fτ,(gy
′
vc
′
). When that happens, we have
μ (gyvc)2
τ
= μ
(
gy
′
vc
′)2τ
mod n mod 2
Here is the algorithm that extracts these values from the adversary A. We write
Success(ω, c1, . . . , cn) the result of the identification of A using the challenges
c1, . . . , cn, for some random tape ω.
Step 1. Pick a random tape ω and a tuple c of N integers c1, . . . , cN in [0, B−1].
If Success(ω, c) = false, then abort.
Step 2. Probe random N -tuples c′ that are different from each other and from
c, until Success(ω, c′) = true. If after BN − 1 probes a successful c′ has
not been found, abort.
Step 3. Let j be the first index such that cj = c′j , write yj and y′j the corre-
sponding answers of A. Output cj , c′j , yj , y′j .
This algorithm succeeds with probability ≥ 
 − 1/BN = 
′, and takes at most
4Δmax units of time [12]. This means that there is an algorithm finding collisions
in fτ, with probability ≥ 
′ and time ≤ 4Δmax.
Assuming the hardness of the discrete logarithm with short exponents prob-
lem, the adversary responds in time by solving a hard problem, where as pointed
out earlier the probability of success is given by
ζ =
κ log(B) log(S)λ
ν2τ
Slow Motion Zero Knowledge Identifying with Colliding Commitments 391
where κ is the number of concurrent evaluations of fτ, performed by A. There is
a value of τ such that ζ  
. For this choice of τ , A is able to compute fτ, much
faster than brute-force, which contradicts the time-lock hardness assumption. 
6 Conclusion and Further Research
This paper introduced a new class of protocols, called Slow Motion Zero Knowl-
edge (SM-ZK) showing that if we pay the conceptual price of allowing time
measurements during a three-pass ZK protocol then commitments do not need
to be collision-resistant.
Because of its interactive nature, SM-ZK does not yield signatures but seems
to open new research directions. For instance, SM-ZK permits the following
interesting construction, that we call a fading signature: Alice wishes to send a
signed message m to Bob without allowing Bob to keep a long-term her involve-
ment. By deriving c ← H(x,m, ρ) where ρ is a random challenge chosen by Bob,
Bob can convince himself3 that m comes from Alice. This conviction is however
not transferable if Alice prudently uses a short commitment as described in this
paper.
A Proof of Lemma2
Proof. The zero-knowledge property of the standard GPS protocol is proven
by constructing a polynomial-time simulation of the communication between a
prover and a verifier [12, Theorem 2]. We adapt this proof to the context of the
proposed protocol. The function δ is defined by δ(true) = 1 and δ(false) = 0, and
∧ denotes the logical operator “and”. For clarity, the function fτ, is henceforth
written f .
The scenario is that of a prover P and a dishonest verifier A who can use an
adaptive strategy to bias the choice of the challenges to try to obtain information
about s. In this case the challenges are no longer chosen at random, and this
must be taken into account in the security proof. Assume the protocol is run N
times and focus on the i-th round.
A has already obtained a certain amount of information η from past interac-
tions with P. P sends a pre-computed commitment xi. Then A chooses a com-
mitment using all information available to her, and a random tape ω: ci (xi, η, ω).
The following is an algorithm (using its own random tape ωM ) that simulates
this round:
Step 1. Choose ci
$←− [0, B − 1] and yi $←− [(B − 1)(S − 1), A − 1] using ωM .
Step 2. Compute xi = fτ,
(
gyivci
)
.
3 If y was received before Δmax.
392 H. Ferradi et al.
Step 3. If ci (xi, η, ω) = ci then return to step 1 and try again with another pair
(ci, yi), else return (xi, ci, yi).4
The rest of the proof shows that, provided Φ = (B−1)(S−1) is much smaller
than A, this simulation algorithm outputs triples that are indistinguishable from
real ones, for any fixed random tape ω.
Formally, we want to prove that
Σ1 =
∑
α,β,γ
∣
∣
∣
∣PrωP
[(x, c, y) = (α, β, γ)] − Pr
ωM
[(x, c, y) = (α, β, γ)]
∣
∣
∣
∣
is negligible, i.e., that the two distributions cannot be distinguished by accessing
a polynomial number of triples (even using an infinite computational power). Let
(α, β, γ) be a fixed triple, and assuming a honest prover, we have the following
probability:
p = Pr
ωP
[(x, c, y) = (α, β, γ)]
= Pr
0≤r<A
[α = f(gr) ∧ β = c(α, η, ω) ∧ γ = r + βs]
=
A−1∑
r=0
1
A
δ
(
α = f(gγvβ) ∧ β = c(α, η, ω) ∧ r = γ − βs)
=
1
A
δ
(
α = f(gγvβ) ∧ β = c(α, η, ω) ∧ γ − βs ∈ [0, A − 1])
=
1
A
δ
(
α = f(gγvβ)
)
δ (β = c(α, η, ω)) δ (γ − βs ∈ [0, A − 1]) .
where f = fτ,.
We now consider the probability p = PrωM [(x, c, y) = (α, β, γ)] to obtain
the triple (α, β, γ) during the simulation described above. This is a conditional
probability given by
p = Pr
y∈[Φ,A−1]
c∈[0,B−1]
[
α = f
(
gyvc
) ∧ β = c ∧ γ = y ∣∣ c = c (f (gyvc) , η, ω)]
Using the definition of conditional probabilities, this equals
p =
Pr
y∈[Φ,A−1]
c∈[0,B−1]
[
α = f
(
gyvc
) ∧ β = c ∧ γ = y]
Pr
y∈[Φ,A−1]
c∈[0,B−1]
[c = c (f (gyvc) , η, ω)]
Let us introduce
Q =
∑
y∈[Φ,A−1]
c∈[0,B−1]
δ
(
c = c
(
f
(
gyvc
)
, η, ω
))
4 The probability of success at step 3 is essentially 1/B, and the expected number of
executions of the loop is B, so that the simulation of N rounds runs in O(NB): the
machine runs in expected polynomial time.
Slow Motion Zero Knowledge Identifying with Colliding Commitments 393
then the denominator in p is simply Q/B(A − Φ). Therefore:
p =
∑
c∈[0,B−1]
1
B
Pr
y∈[Φ,A−1]
[
α = f
(
gyvc
) ∧ γ = y ∧ β = c = c(α, η, ω)] B(A − Φ)
Q
= Pr
y∈[Φ,A−1]
[
α = f
(
gγvβ
) ∧ γ = y ∧ β = c(α, η, ω)] A − Φ
Q
=
∑
y∈[Φ,A−1]
1
A − Φδ
(
α = f
(
gγvβ
) ∧ γ = y ∧ β = c(α, η, ω)) A − Φ
Q
=
1
Q
δ
(
α = f
(
gγvβ
))
δ (β = c(α, η, ω)) δ (γ ∈ [Φ,A − 1])
We will now use the following combinatorial lemma:
Lemma 4. If h : G → [0, B − 1] and v ∈ {g−s, s ∈ [0, S − 1]} then the total
number M of solutions (c, y) ∈ [0, B −1]× [Φ,A−1] to the equation c = h(gyvc)
satisfies A − 2Φ ≤ M ≤ A.
Proof. (Proof of Lemma 4) [12, Appendix A]. Specialising Lemma4 to the func-
tion that computes c(f(gyvc), η, ω) from (c, y) gives A − 2Φ ≤ Q ≤ A. This
enables us to bound Σ1:
Σ1 =
∑
α,β,γ
∣
∣
∣
∣PrωP
[(x, c, y) = (α, β, γ)] − Pr
ωM
[(x, c, y) = (α, β, γ)]
∣
∣
∣
∣
=
∑
α,β,γ∈[Φ,A−1]
∣
∣
∣
∣PrωP
[(x, c, y) = (α, β, γ)] − Pr
ωM
[(x, c, y) = (α, β, γ)]
∣
∣
∣
∣
+
∑
α,β,γ /∈[Φ,A−1]
Pr
ωP
[(x, c, y) = (α, β, γ)]
=
∑
γ∈[Φ,A−1]
β∈[0,B−1]
α=f(gγvβ)
∣
∣
∣
∣
1
A
δ (β = c(α, η, ω)) − 1
Q
δ(β = c(α, η, ω))
∣
∣
∣
∣
+
⎛
⎝1 −
∑
α,β,γ∈[Φ,A−1]
Pr
ωP
[(x, c, y) = (α, β, γ)]
⎞
⎠
=
∣
∣
∣
∣
1
A
− 1
Q
∣
∣
∣
∣ Q + 1 −
∑
γ∈[Φ,A−1]
β∈[0,B−1]
α=f(gγvβ)
1
A
δ (β = c(α, η, ω))
=
|Q − A|
A
+ 1 − Q
A
Therefore Σ1 ≤ 2|Q − A|/A ≤ 4Φ/A < 4SB/A, which proves that the
real and simulated distributions are statistically indistinguishable if SB/A
is negligible. 
394 H. Ferradi et al.
B GPS Commitment Pre-computation
Figure 4 described one possible way in which pre-computed commitments are
generated and used for GPS. In this figure, we delegate the computation to
a trusted authority. That role can be played by P alone, but we leverage the
authority to alleviate P’s computational burden.
To efficiently generate a sequence of commitments, the authority uses a
shared secret seed J and a cryptographic hash function H. Here J is chosen
by P but it could be chosen by the authority instead.
Fig. 4. Commitment pre-processing as applied to GPS. The first stage describes the
preliminary interaction with a trusted authority, where pre-computed commitments
are generated and stored. The second stage describes the interaction with a verifier.
For the sake of clarity the range-tests on c and y were omitted. The trusted authority
can be easily replaced by P himself.
Slow Motion Zero Knowledge Identifying with Colliding Commitments 395
References
1. Abadi, M., Burrows, M., Manasse, M.S., Wobber, T.: Moderately hard, memory-
bound functions. ACM Trans. Internet Technol. 5(2), 299–327 (2005)
2. Bellare, M., Rogaway, P.: Random oracles are practical: a paradigm for designing
efficient protocols. In: Denning, D.E., Pyle, R., Ganesan, R., Sandhu, R.S., Ashby,
V. (eds.) CCS 1993, Proceedings of the 1st ACM Conference on Computer and
Communications Security, Fairfax, Virginia, USA, 3–5 November, 1993, pp. 62–73.
ACM (1993)
3. Bernstein, R.L.: Multiplication by integer constants. Softw. Pract. Exper. 16(7),
641–652 (1986)
4. Boneh, D., Naor, M.: Timed commitments. In: Bellare, M. (ed.) CRYPTO 2000.
LNCS, vol. 1880, p. 236. Springer, Heidelberg (2000)
5. Ciobotaru, O.: On the (Non-)Equivalence of UC security notions. In: Takagi, T.,
Wang, G., Qin, Z., Jiang, S., Yu, Y. (eds.) ProvSec 2012. LNCS, vol. 7496, pp.
104–124. Springer, Heidelberg (2012)
6. Damg̊ard, I.: On Σ Protocols (2010). http://www.cs.au.dk/∼ivan/Sigma.pdf
7. Dwork, C., Goldberg, A.V., Naor, M.: On memory-bound functions for fighting
spam. In: Boneh, D. (ed.) CRYPTO 2003. LNCS, vol. 2729, pp. 426–444. Springer,
Heidelberg (2003)
8. Dwork, C., Naor, M.: Pricing via processing or combatting junk mail. In:
Brickell, E.F. (ed.) CRYPTO 1992. LNCS, vol. 740, pp. 139–147. Springer,
Heidelberg (1993)
9. Dwork, C., Naor, M., Wee, H.M.: Pebbling and proofs of work. In: Shoup, V. (ed.)
CRYPTO 2005. LNCS, vol. 3621, pp. 37–54. Springer, Heidelberg (2005)
10. Feige, U., Fiat, A., Shamir, A.: Zero-knowledge proofs of identity. J. Cryptology
1(2), 77–94 (1988)
11. Girault, M.: An identity-based identification scheme based on discrete logarithms
modulo a composite number. In: Damg̊ard, I.B. (ed.) EUROCRYPT 1990. LNCS,
vol. 473, pp. 481–486. Springer, Heidelberg (1991)
12. Girault, M., Poupard, G., Stern, J.: On the fly authentication and signature
schemes based on groups of unknown order. J. Cryptology 19(4), 463–487 (2006)
13. Girault, M., Stern, J.: On the length of cryptographic hash-values used in iden-
tification schemes. In: Desmedt, Y.G. (ed.) CRYPTO 1994. LNCS, vol. 839, pp.
202–215. Springer, Heidelberg (1994)
14. Goldreich, O., Micali, S., Wigderson, A.: Proofs that yield nothing but their validity
for all languages in NP have zero-knowledge proof systems. J. ACM 38(3), 691–729
(1991)
15. Goldwasser, S., Micali, S., Rackoff, C.: The knowledge complexity of interactive
proof-systems (extended abstract). In: Sedgewick, R. (ed.) Proceedings of the 17th
Annual ACM Symposium on Theory of Computing, 6–8 May, 1985, Providence,
Rhode Island, USA, pp. 291–304. ACM (1985)
16. Hazay, C., Lindell, Y.: Efficient secure two-party protocols: techniques and con-
structions. Springer Science and Business Media, Heidelberg (2010)
17. Mahmoody, M., Moran, T., Vadhan, S.: Time-lock puzzles in the random oracle
model. In: Rogaway, P. (ed.) CRYPTO 2011. LNCS, vol. 6841, pp. 39–50. Springer,
Heidelberg (2011)
18. Micali, S., Pass, R.: Local zero knowledge. In: Kleinberg, J.M. (ed.) Proceedings of
the 38th Annual ACM Symposium on Theory of Computing, Seattle, WA, USA,
21–23 May, 2006, pp. 306–315. ACM (2006)
396 H. Ferradi et al.
19. M’Räıhi, D., Naccache, D.: Couponing scheme reduces computational power
requirements for dss signatures. In: Proceedings of CardTech/SecurTech, pp. 99–
104 (1994)
20. Poupard, G., Stern, J.: Security analysis of a practical “On the Fly” authentication
and signature generation. In: Nyberg, K. (ed.) EUROCRYPT 1998. LNCS, vol.
1403, pp. 422–436. Springer, Heidelberg (1998)
21. Rivest, R., Shamir, A., Wagner, D.: Time-lock puzzles and timed-release crypto,
technical report, MIT/LCS/TR-684 (1996)
22. de Rooij, P.: On schnorr’s preprocessing for digital signature schemes. J. Cryptol-
ogy 10(1), 1–16 (1997)
Multi-client Outsourced Computation
Peili Li1,2,3, Haixia Xu1,2(B), and Yuanyuan Ji1,2,3
1 State Key Laboratory of Information Security,
Institute of Information Engineering of Chinese Academy of Sciences,
Beijing, China
{plli,hxxu}@is.ac.cn, jiyuanyuan@iie.ac.cn
2 Data Assurance and Communication Security Research Center
of Chinese Academy of Sciences, Beijing, China
3 University of Chinese Academy Sciences, Beijing, China
Abstract. In this paper, we study multi-client outsourced computation
where n computationally weak clients outsource their computation of a
function f over their joint inputs (x1, · · · , xn) to remote servers. Some
prior works consider outsourcing computation to an untrusted server.
However these schemes either are inefficient, make the clients’ status
unequal or require client interactions. Based on prior works, we con-
struct an efficient multi-client outsourced computation scheme using two
servers. Our scheme avoids interactions among all the parties and it is
secure against one malicious server. Furthermore it is public verifiable
that any client can verify the correctness of the computation result using
a public verify key.
Keywords: Multi-client · Outsourced computation · Cloud computing ·
Privacy · Efficient · Public verification
1 Introduction
Cloud computing has been rapidly developed recent years. The cloud not only
offer data storage service but also help companies or users to accomplish their
computation tasks. This trend contributes to the study of outsourced computa-
tion where a computationally weak client outsources its computation of a func-
tion f to a powerful server [6]. Outsourced computation has several real applica-
tions. For example, in cloud computing, businesses outsource their computation
to a service and pay the computing time rather than purchasing and maintaining
the computing devices. It helps companies save costs and can mainly focus on
their key services. Outsourced computation is also useful in weak mobile devices
such as smart phones, net books that would like to outsource a computation(e.g.,
a photo manipulation) to a remote server.
Some earlier works about outsourced computation consider single-client sce-
nario [2,4–6,12] where the functionality only works on one client’s input. While
in some cases, several resource-constrained clients may want to jointly do some
c© Springer International Publishing Switzerland 2016
D. Lin et al. (Eds.): Inscrypt 2015, LNCS 9589, pp. 397–409, 2016.
DOI: 10.1007/978-3-319-38898-4 23
398 P. Li et al.
computation. It would be desirable to study multi-client outsourced computa-
tion where n clients wish to outsource the computation of a function f over a
series of joint inputs (x1, · · · , xn) to a remote server [3].
In outsourced computation, we can not ensure that the remote server is
honest. Thus two security problems should be considered: one is keeping privacy
of the outsourced data from the server, the other one is verifying the correctness
of the computation result returned from the untrusted server. In addition to these
two problems, in multi-client outsourced computation we should consider how to
keep privacy of the clients’ inputs from each other. Furthermore another problem
is whether the verification of the computation can be public: any other client can
verify the correctness of the computation result returned from the server using a
public verify key [5]. This is important, for example, a lab assistant outsourced a
computation on input x, he may need to produce a verification key that will let
the patients obtain the answer from the cloud and check its correctness. In this
paper, we mainly study the problems of multi-client outsourced computation
and construct an efficient non-interactive multi-client outsourced computation.
1.1 Related Work
Multi-client Outsourced Computation. Choi et al. [3] first introduced the
notion of multi-client verifiable computation(MVC) and constructed a MVC
scheme secure against a malicious server. It is efficient in the sense of amor-
tization. Later Gordon et al. [9] designed a MVC scheme with stronger security
guarantees (satisfies a simulation-based notion of security). In their scheme the
clients’ cost depends on the depth of the function f being computed. Goldwasser
et al. [7] showed that multi-input functional encryption can be used to design
publicly verifiable multi-client outsourcing scheme(any other client can verify the
correctness of computation result using a public verify key). These three works
talked above all can keep privacy of the clients inputs and are secure against a
malicious server. However, in both [3,9]’s schemes, only one client can do the
verification and get the computation result in every execution, which makes the
clients’ status unequal. Although [7]’s construction is public verifiable, its privacy
property relies on a completely honest client who generates the master secret
key(MSK). The cost of the clients in these above three works is closely related
to the function f being computed. López-Alt et al. [11] proposed a multi-key
homomorphic encryption scheme which can be used in multi-client outsourced
computation, but the clients need to interactively compute the decryption key
in order to get the computation result.
In order to improve the clients’ efficiency and avoid interactions among the
clients, Peter et al. [13] designed an efficient multi-client outsourcing scheme
using BCP encryption scheme and two noncolluding servers. What the clients
need to do is just the encryption and decryption process, thus their cost is inde-
pendent of the function f being computed. However their scheme is secure in
the semi-honest model and complex interactions are needed between these two
servers. Utilizing Proxy Re-Encryption scheme Wang et al. [16] constructed an
Multi-client Outsourced Computation 399
efficient multi-client outsourced computation scheme that requires minimal inter-
actions between these two servers. Similar to [13,16]’s works, [15] constructed
a multi-client outsourced computation scheme using lattice-based encryption
scheme and two noncolluding servers. These three works all avoid interactions
among the clients and the clients’ computation cost is independent of the func-
tion f being computed, but they are only secure in the semi-honest model and
need server interactions. Jakobsen et al. [14] designed a framework for outsourc-
ing multi-client computation to multiple servers. It is secure when at least one
of the server is honest. Their solution is generic and can be instantiated with
reactive Multiparty Computation(MPC) protocol. However,their work is only
secret verifiable and the servers in [14] also need to do interactions in order to
accomplish the computation.
In this work, we aim to design an efficient multi-client outsourced computa-
tion scheme that avoids interactions among the clients and the servers. And we
want to make the scheme public verifiable such that all the clients can verify
and obtain the computation result during one execution. Furthermore we try to
make the scheme secure against a malicious server. Our basic idea comes from
Choi et al.’s work [3], so we describe it in details next.
Details About Choi et al.’s Work. In their scheme, to securely compute a
function f , one client(suppose client 1) generates a garbled circuit Γ of f and
sends Γ to the server. Only after receiving the labels corresponding to the clients’
inputs (x1, · · · , xn), can the server compute the garbled circuit Γ . While only
client 1 who generates the garbled circuit has the input-wire labels, but it does
not know the inputs of other clients and it can not send all the input-wire labels
to anyone else. Thus how can the server obtain the labels corresponding to other
clients’ inputs? To solve this problem, They used a tool called proxy oblivious
transfer protocol(proxy OT). In proxy OT, client 1 acts as a sender, client i(i =1)
acts as a chooser and the server is a proxy. After the protocol, the proxy can
only learn the labels corresponding to chooser’s input and the chooser’s input is
kept private. This is a novel idea to extend Gennaro et al.’s one-client outsourced
computation scheme [6] to multi-client outsourced computation scheme. In [3]’s
construction, only the client who generates the garbled circuit can verify and get
the computation result f(x1, · · · , xn). These n clients need to run the scheme n
times in order to ensure all of them can verify and get the output. Thus all the
clients need to generate the garbled circuit of function f , and the computation
cost of the clients are closely related to the function f being computed.
1.2 Our Contribution
We design an efficient multi-client outsourced computation scheme using two
noncolluding servers. In our scheme, the clients’ inputs are keeping private from
each other and the two servers. Our scheme has these following features:
– The computation cost of the clients is independent of the function f being
computed. See Table 1 below.
400 P. Li et al.
Table 1. Comparisons with related work
Work Client’s cost
Choi et al. [6] Only efficient in amortization
Goldwasser et al. [8] O(|skf | · lk)
Gordon et al. [7] O(d · nlk)
Our work O(lk)
– Our scheme avoids interactions among all the parties (the clients and two
servers).
– Our outsourced computation scheme is publicly verifiable that any other client
can verify the correctness of the computation result.
– It is secure against one malicious server in the two-server setting(we assume
that the other server is semi-honest).
In Table 1, d is the depth of the function f being computed, l is the input
length and k is the security parameter. skf is the secret key corresponding to
function f in [8]’s multi-input functional encryption scheme.
1.3 Paper Organization
The rest of this paper is organized as follows. In Sect. 2 we introduce the tool that
will be used in our scheme. In Sect. 3 we talk about the model and techniques
used in our scheme. In Sect. 4 we show the construction of multi-client outsourced
computation scheme. Finally, in Sect. 5 we make the conclusion.
2 Preliminaries
We denote k the security parameter, negl(·) a negligible function and PPT the
probabilistic polynomial time. Denote Dom(F ) the domain of the function set
F and
∏
the protocol of multi-client outsourced computation scheme.
2.1 Garbled Circuits
Garbled circuits were first presented by Yao [17] in the context of secure two-
party computation and were proven secure by Lindell and Pinkas [10]. The notion
was formalized by Bellare et al. [1] and was simplified by Goldwasser et al. [8].
In this paper, we refer to [8]’s definition of the garbling scheme for simplicity.
Definition 1 (Garbling Scheme). [8] Cn is the set of circuit taking as input
n bits. A garbling scheme for a family of circuits C = {Cn}n∈N , is a tuple of
PPT algorithms Gb= (Gb.Garble, Gb.Enc, Gb.Eval, Gb.Dec) such that
1. Gb.Garble(1k, C) takes as input the security parameter k and a circuit C ∈ Cn
for some n, and outputs the garbled circuit Γ and a secret key sk.
Multi-client Outsourced Computation 401
2. Gb.Enc(sk, x) takes as input the secret key sk and data x ∈ {0, 1}n and
outputs an encoding c.
3. Gb.Eval(Γ, c) takes as input a garbled circuit Γ , an encoding c and outputs a
value y .
4. Gb.Dec(d,Y) takes as input decoding key d and the garbled output Y , maps
Y to a final output y.
Correctness. For any polynomial n(·), for all sufficiently large security para-
meters k, for n = n(k), for all circuits C ∈ Cn and all x ∈ {0, 1}n, Pr[(Γ, sk) ←
Gb.Garble(1k, C); c ← Gb.Enc(sk, x); y ← Gb.Eval(Γ, c) : C(x) = y] = 1 −
negl(k).
Input and Circuit Private. If there exist a ppt simulator SimGarble, such that
for every ppt adversaries A and D, for all sufficiently large security parameters
k, the following equation holds. Then the garbled scheme Gb for a family of
circuits {Cn}n∈N is input and circuit private.
|Pr[(x,C, α) ← A(1k); (Γ, sk) ← Gb.Garble(1k, C);
c ← Gb.Enc(sk, x) : D(α, x,C, Γ, c)]
−Pr[(x,C, α) ← A(1k); (Γ̃ , c̃)
← SimGarble(1k, C(x), 1|C|, 1|x|) : D(α, x,C, Γ̃ , c̃)]| = negl(k)
Additionally we require that the garbling scheme satisfies authenticity [3].
Authenticity. We say that a garbling scheme provides authenticity if for any
PPT adversary learning a set of labels to some input x is unable to produce a
set of labels that corresponds to an output different from f(x).
The garbling scheme used in our protocol is a projective garbling scheme
which means that the encryption algorithm treat the input in pieces instead of
processing the whole input at once. In our work, each encoding only depends on
one bit of the input. For example, let x = x1, · · · , xn ∈ {0, 1}n, the encryption
algorithm needs to generate encoding for each xi(i ∈ [n]). In the rest of this
paper, the word ‘label’ denotes the encoding in the garbling scheme.
3 Our Model and Techniques
3.1 Multi-client Outsourced Computation Scheme
Refer to the description of Choi et al.’s work [3], we give a model of multi-client
outsourced computation scheme in the two-server setting. We denote the two
servers S1,S2. Fig. 1 gives the model of the multi-client outsourced computation
in two-server setting.
In Fig. 1, Z and V Ky are the messages returned by the two servers.
Security Model: In the two-server setting, we consider the security against one
malicious server(S2) and one semi-honest server(S1). Our scheme assumes that
402 P. Li et al.
Fig. 1. Multi-client outsourced computation
the clients know which server is semi-honest in advance. Informally, we say that
a multi-client outsourced computation scheme is secure if it can keep privacy
the clients’ inputs from each other and the two servers, and a malicious server
S2 can not forge an incorrect message Z that makes the clients accept. In this
paper, we analyze its security using the real-ideal paradigm.
In the real world, all parties together with these two servers run the pro-
tocol
∏
to get the desired output. During the protocol, all the clients and the
server S1 follow the protocol semihonestly. An adversary A can corrupt server
S2 and attempts to gain more information about the clients’ inputs and forge
an incorrect computation result that can pass the verification.
In the ideal world, the clients send their inputs and a function f to a trusted
third party(TTP). Then TTP will do the computation of function f on the
clients’ inputs (x1, · · · , xn) and obtain f(x1, · · · , xn). After that, TTP will send
function f to the ideal world simulator S. If S returns yes, then TTP will send
f(x1, · · · , xn) to the clients. Otherwise, TTP will return abort.
We denote IDEALF,S(x1, · · · , xn) the joint execution of f under the Simula-
tor S in the ideal world on input (x1, · · · , xn). REAL∏,A(x1, · · · , xn) the joint
execution of
∏
under A in the real world on input (x1, · · · , xn).
Definition 2 (Multi-client Outsourced Computation). A multi-client
outsourced computation scheme in the two server setting consists the following
four algorithms:
1. KeyGen(1k) → (PK,SK): Takes input the security parameter k, the algo-
rithm generates a key pair (PK,SK).
2. ProbGen(PK, f, x1, · · · , xn) → (c1, c2): Takes input the public key PK, func-
tion f being computed, and n clients’ inputs (x1, · · · , xn), the algorithm com-
putes ciphertext c1 and c2, sends c1 and f to server S1 and c2 to server S2.
3. Compute(PK, c1, c2, f) → (V Ky, Z): Given the public key PK, server S1
with input (c1, f) and server S2 with input c2 corporately compute a message
Z and a verify-message V Ky, and then send them to the clients.
4. Verify(V Ky, Z) → (y, reject): Using public verify message V Ky, the algo-
rithm verifies the correctness of Z. If the verification passed, the correspond-
ing result y can be recovered after the verification. Otherwise reject.
Multi-client Outsourced Computation 403
Correctness: A multi-client outsourced computation scheme is correct if for
any function f ∈ F and any (SK,PK) ← KeyGen(1k, f), any (x1, · · · , xn) ∈
Dom(F ), if (c1, c2) ← ProbGen(PK, x1, · · · , xn) and (V Ky, Z) ←
Compute(PK, c1, c2, f), then y = f(x1, · · · , xn) ← Verify(V Ky, Z) holds with
all but negligible probability.
Security: A multi-client outsourced computation scheme is secure if for any
PPT adversary A in the real world, there exists a PPT simulator S in the ideal
world such that for all (x1, · · · , xn) no PPT distinguisher D is able to distinguish
IDEALF,S(x1, · · · , xn) from REAL∏,A(x1, · · · , xn).
3.2 Techniques
In this part, we talk about the techniques in our protocol. Our basic idea comes
from Choi et al.’s work [3]. In Sect. 1.1 we have showed that the computation
cost of the clients are closely related to the function f being computed.
To reduce the computation cost of the clients, we use a semi-honest server
S1 to generate the garbled circuit Γ of function f . One directly thinking is just
let the semi-honest server S1 to compute the garbled circuit with the labels
corresponding to clients’ inputs and send the computation result to the clients.
While in this situation, the clients’ inputs can not be kept private from S1 for
the garbled circuit is generated by S1. Thus we need to separate the garbled
circuit generation process from the computation process of the garbled circuit.
Let the computation process done by another server S2.
In our construction, let S1 send Γ to the other server S2. Then S2 computes
the garbled circuit Γ with the labels corresponding to (x1, · · · , xn). For S1 and S2
do not know the inputs of the clients and only S1 know all the input-wire labels.
How can S2 get the labels corresponding to (x1, · · · , xn)? A nature thought is to
directly use [3]’s proxy OT protocol. Each client together with S1, S2 involved
in the proxy OT protocol. While in proxy OT each client needs to run a key-
exchange protocol with S1. Every time, the clients and the server S1 need to run
the setup algorithm to generate their key pairs. To reduce the key generation
process, we design a new protocol π for choosing labels.
Choose Labels. In protocol π, we use a public key encryption (PKE) scheme
to encrypt the randomness elements and a one-time pad encryption scheme to
encrypt the client’s input. The protocol π is designed as followings:
– π.Setup(1k): Server S1 runs a public key encryption scheme(PKE) to generate
its key pair (PK,SK).
– π.Client(x, PK): The client with its input x(|x| = l). It chooses 2l ran-
dom elements (r01, r
1
1, · · · , r0l , r1l ) with the same length k and a random
element t (|t| = l). Denote r = (r01, r11, · · · , r0l , r1l ). The client computes
c1=PKE.EncPK(r, t) and c2 = (x ⊕ t, rx11 , · · · , rxll ). Sends c1 to server S1
and c2 to server S2.
– π.S1(c1,k, SK): S1 holds the labels k = (k01, k
1
1, · · · , k0l , k1l ). S1 decrypts c1
using its secret key SK and obtains (r, t). Computes wtjj = r
0
j ⊕ k0j , w1⊕tjj =
r1j ⊕ k1j for all j ∈ [l]. Let w = (w01, w11, · · · , w0l , w1l ) and sends w to server S2.
404 P. Li et al.
– π.S2(w, c2): w = (w01, w
1
1, · · · , w0l , w1l ), parse c2 as (d, rx11 , · · · , rxll ). S2 com-
putes kj = w
dj
j ⊕ rxjj for all j ∈ [l].
The above protocol π acts as a sub-protocol of our multi-client outsourcing
scheme
∏
. In our work, let each client run the sub-protocol π with the two
servers S1 and S2 synchronously. After executing the protocol, server S2 can get
the labels corresponding to the inputs of all clients.
Public Verification. After solving the problem of how to choose labels, server
S2 can compute the garbled circuit Γ . Another problem is how to verify the
correctness of the result returned from S2. Similar to the idea of [6], the output
of the garbled circuit are the labels corresponding to the output bits. We use
the garbling scheme that satisfies authenticity property. The decoding key d
consists of the wire values chosen. After receiving a message Z returned from
the server, the client maps the message Z to an output y using the decoding key
d. If the map process passed, we say that server honestly do the computation of
function f .
In this paper, We aim to design a public verify method that all the clients
can verify the correctness of the computation result and obtain f(x1, · · · , xn).
Observe that the output of the garbled circuit Γ is the label corresponding to
f(x1, · · · , xn)(For simplicity, we assume that the output of the function f is one
bit). Let k0y, k
1
y be the labels of the output-wire. If f(x1, · · · , xn) = 0, Γ outputs
label k0y, else if f(x1, · · · , xn) = 1 outputs k1y. Let server S1 compute a one-way
function g on k0y and k
1
y and make g(k
0
y), g(k
1
y) public. After server S2 returns
message Z to the clients, all the clients can compute g(Z) and verify whether it
is equal to g(k0y) or g(k
1
y). If g(Z) = g(k
0
y), outputs 0, if g(Z) = g(k
1
y), outputs
1. Otherwise reject.
4 Our Construction
Now we are ready to describe our construction of multi-client outsourced compu-
tation scheme(denote
∏
) in the two-server setting. We use a garbling scheme and
the protocol π designed in Sect. 3 as our tools. Suppose server S1 is semi-honest.
The scheme
∏
is designed as followings:
1. KeyGen(1k) → (PK,SK): The semi-honest server S1 runs π.Setup algorithm
and obtains a key pair (PK,SK).
2. ProbGen(PK, f, x1, · · · , xn) → (c1, c2): Each client i (i ∈ [n]) runs π.Client
algorithm with its input xi to creates its ciphertext ci = (c1i , c
2
i ), and sends
c1i and function f to server S1, sends c
2
i to server S2. Let c
1 = (c11, · · · , c1n),
c2 = (c21, · · · , c2n).
3. Compute(PK,SK, c1, c2, f) → Z: The computation process can be divided
into two parts that are done by S1 and S2 respectively.
– After receiving c1 = (c11, · · · , c1n) and function f , S1 first computes the
garbled circuit Γ of function f . Parse (k0y, k
1
y) as the labels of the output-
wire. S1 computes V Ky = (g(k0y), g(k
1
y)) and makes them public(here g is
a one-way function).
Multi-client Outsourced Computation 405
S1 having SK runs π.S1 algorithm n time to generate messages τ1, · · · , τn
respectively. τi is the output of π.S1 algorithm with inputs (c1i ,ki) (here ki
are the labels of client i’s input-wires). After that S1 sends τ = (τ1, · · · , τn)
and Γ to S2.
– After receiving c2 = (c21, · · · , c2n) from the clients and (τ, Γ ) from S1, the
second server S2 runs π.S2 algorithm respectively to obtain the labels
corresponding to each client’s input. Using these labels, S2 computes the
garbled circuit Γ to obtain the output message Z and sends Z to the
clients.
4. Verify(V Ky, Z) → (y, reject): Using public verify message V Ky =
(g(k0y), g(k
1
y)), each client computes g(Z) and verifies whether it is equal to g(k
0
y)
or g(k1y). If g(Z) = g(k
0
y), outputs 0, if g(Z) = g(k
1
y), outputs 1. Otherwise reject.
Efficiency Analysis. From the above construction, we can see that the clients
only need to run the PKE scheme to generate their ciphertexts and then later
run the one-way function to verify the correctness of the computation result.
The computation cost of the clients is only depend on the their input length l
and the security parameter k. The efficiency comparison with other verifiable
outsourced computation schemes is given in Table 1 in Sect. 1.2.
4.1 Correctness and Security Proof
Theorem 1 (Correctness). If the underlying garbling scheme and PKE
scheme are correct, then the above scheme
∏
is a correct multi-client outsourced
computation scheme.
Proof: In our construction, we use the sub-protocol π to choose the labels cor-
responding to the clients’ inputs. For the PKE and one-time pad encryption
scheme in π is correct, it is easy to verify that the output of S2 in the sub-
protocol π are (kx11 , · · · , kxll ) which are the labels corresponding to x. And we
use garbling scheme to securely compute function f on the inputs (x1, · · · , xn).
Due to the correctness of the garbling scheme, the output of our scheme
∏
is
f(x1, · · · , xn). Thus our scheme is a correct multi-client outsourced computation
scheme.
Theorem 2 (Security). Suppose the garbling scheme we use is input and cir-
cuit private and provides authenticity, the PKE scheme is secure, and the one-
time pad encryption scheme is secure, then our scheme
∏
is secure against a
malicious server(S2) and a semi-honest server(S1).
Proof: We prove the security using the real-ideal model described in Sect. 2 (refer
to Fig. 2). A is an PPT adversary that corrupts server S2.
We say that a multi-client outsourced computation scheme is secure if for any
PPT adversary A in the real world there exists a PPT simulator S with black-
box access to A such that for all (x1, · · · , xn) no PPT environment D is able to
distinguish IDEALF,S(x1, · · · , xn) from REAL∏,A(x1, · · · , xn). The Simulator
S in the ideal world acts as following(refer to Fig. 3 for better understanding):
406 P. Li et al.
Fig. 2. Real-ideal model
Fig. 3. Ideal world
The Simulator S
– After receiving function f from the trusted third party(TTP), the simulator S
generates a garbled circuit Γ of function f . It then runs the π.client algorithm
n times each with input 0l to generates c′1i (i = 1, · · · , n) and c′2i (i = 1, · · · , n).
Using the labels of the garbled circuit and the randomness chosen in running
π.Client algorithm, the simulator can directly compute τ ′ = (τ ′1, · · · , τ ′n). Let
c′1 = (c′11, · · · , c′1n) and c′2 = (c′21, · · · , c′2n). Involve A with inputs (c′2, τ ′,Γ ).
– S generates the public verify message V Ky and then verifies the correctness
of the output of A by running the verify algorithm. If the verification passed,
the simulator S will return yes to TTP, otherwise, return no.
– The output of the simulator is (c′1, c′2, f, τ ′, Γ,A(c′2, τ ′, Γ )).
Next we show that IDEALF,S(x1, · · · , xn) is indistinguishable from REAL∏,A
(x1, · · · , xn).
REAL∏,A(x1, · · · , xn) equals (⊥, c1, c2, f, τ, Γ,A(c2, τ, Γ )) if Verify algo-
rithm return ⊥. Otherwise REAL∏,A(x1, · · · , xn) equals (OUTPUT
∏
(x1, · · · ,
xn), c1, c2, f, τ, Γ,A(c2, τ, Γ )). Here OUTPUT
∏
(x1, · · · , xn) denotes the output
of the clients.
Multi-client Outsourced Computation 407
IDEALF,S(x1, · · · , xn) equals (⊥, S(f)) if the simulator S returns no, oth-
erwise IDEALF,S(x1, · · · , xn) equals (f(x1, · · · , xn), S(f)). For the simulator S
has been constructed above, S(f) equals (c′1, c′2, f, τ ′, Γ,A(c′2, τ ′, Γ )).
We define the following games:
Game 0 is the real world experiment.
Game 1 is the same as Game 0 except that the c1 is the encryption of the
randomness chosen by the simulator S.
Game 2 is the same as Game 1 expect that c2 is the encryption of (0l, · · · , 0l).
Game 3 is the ideal world experiment.
Lemma 1. Assume that the PKE scheme is secure, Game 0 and Game 1 are
computationally indistinguishable.
Proof: The difference between Game 0 and Game 1 is that c1 is the PKE encryp-
tion of two different messages. If there exist a PPT distinguisher D that can
distinguish these two games, the there exist a PPT adversary B that can break
the security of the PKE scheme.
Lemma 2. Assume that the one-time pad encryption scheme is secure and the
garbled circuit is input and circuit private, Game 2 and Game 1 are computa-
tionally indistinguishable.
Proof: The only difference between Game 2 and Game 1 is how c2 computed.
In Game 1, c2 is the encryption of (x1, · · · , xn), while in Game 2 c2 is the
encryption of (0l, · · · , 0l). For the garbling scheme is input and circuit private,
thus the garbled circuit do not reveal any information about the messages. For
these messages (x1, · · · , xn) and (0l, · · · , 0l) are encrypted by the one-time pad
encryption algorithm respectively, if there exist a PPT distinguisher that can
distinguish these two games, then there exist a PPT adversary B that can break
the security of the one-time pad encryption scheme.
Lemma 3. Assume the garbling scheme satisfies authenticity property, then
Game 3 and Game 2 are computational indistinguishable.
Proof: The garbling scheme satisfies authenticity property. If the output of the
semi-honest clients in Game 2 is ⊥, which means that the malicious adversary
A forged an incorrect answer Z. In this case, the Simulator S in the ideal world
will return no to TTP, thus the clients in the ideal world will also output ⊥. In
Game 2, if the output of the semi-honest clients return OUTPUT
∏
(x1, · · · , xn),
it must be f(x1, · · · , xn) due to the authenticity of the garbling scheme. In this
case, the simulator S will return yes to TTP, then the output of the clients
in the ideal world is f(x1, · · · , xn). The distribution of Game 2 and Game 3 is
indistinguishable. From the above lemmas, we get that Game 0 the real world
execution is indistinguishable from Game 3 the ideal world execution.
From the above lemmas, we get that Game 0 the real world execution is
indistinguishable from Game 3 the ideal world execution. 	
408 P. Li et al.
5 Conclusion
In this paper, we design an efficient multi-client outsourced computation scheme
in the two-server setting model. It avoids interactions among all the parties
(the clients and servers), and it is public verifiable that any client can verify the
correctness of the computation result using a public verify key. The computation
cost of the clients is independent from function being computed. Our scheme is
proved to be correct and secure against a malicious server and a semi-honest
server. In the future, it will be interesting to explore an efficient non-interactive
multi-client outsourced computation scheme that is secure against two malicious
servers.
Acknowledgement. This work is supported by the National Natural Science Foun-
dation of China (No. 61379140), the National Basic Research Program of China (973
Program) (No. 2013CB338001). The authors would like to thank anonymous reviewers
for their helpful comments and suggestions.
References
1. Bellare, M., Hoang, V.T., Rogaway, P.: Garbling schemes. IACR Cryptology ePrint
Archive, vol. 2012, p. 265 (2012)
2. Benabbas, S., Gennaro, R., Vahlis, Y.: Verifiable delegation of computation over
large datasets. In: Rogaway, P. (ed.) CRYPTO 2011. LNCS, vol. 6841, pp. 111–131.
Springer, Heidelberg (2011)
3. Choi, S.G., Katz, J., Kumaresan, R., Cid, C.: Multi-client non-interactive verifi-
able computation. In: Sahai, A. (ed.) TCC 2013. LNCS, vol. 7785, pp. 499–518.
Springer, Heidelberg (2013)
4. Chung, K.-M., Kalai, Y., Vadhan, S.: Improved delegation of computation using
fully homomorphic encryption. In: Rabin, T. (ed.) CRYPTO 2010. LNCS, vol.
6223, pp. 483–501. Springer, Heidelberg (2010)
5. Dario, F., Rosario, G.: Publicly verifiable delegation of large polynomials and
matrix computations, with applications. In: 2012 ACM Conference on Computer
and Communication Security. ACM Press (2012). http://eprint.iacr.org/2012/281
6. Gennaro, R., Gentry, C., Parno, B.: Non-interactive verifiable computing: outsourc-
ing computation to untrusted workers. In: Rabin, T. (ed.) CRYPTO 2010. LNCS,
vol. 6223, pp. 465–482. Springer, Heidelberg (2010)
7. Goldwasser, S., Goyal, V., Jain, A., Sahai, A.: Multi-input functional encryption.
IACR Cryptology ePrint Archive, vol. 2013, p. 727 (2013)
8. Goldwasser, S., Kalai, Y., Popa, R.A., Vaikuntanathan, V., Zeldovich, N.: Reusable
garbled circuits and succinct functional encryption. In: Proceedings of the Forty-
Fifth Annual ACM Symposium on Theory of Computing, pp. 555–564. ACM (2013)
9. Gordon, S.D., Katz, J., Liu, F.-H., Shi, E., Zhou, H.-S.: Multi-client verifiable
computation with stronger security guarantees. In: Dodis, Y., Nielsen, J.B. (eds.)
TCC 2015, Part II. LNCS, vol. 9015, pp. 144–168. Springer, Heidelberg (2015)
10. Lindell, Y., Benny, P.: A proof of security of Yao’s protocol for two-party compu-
tation. J. Cryptol. 22(2), 161–188 (2009)
Multi-client Outsourced Computation 409
11. López-Alt, A., Tromer, E., Vaikuntanathan, V.: On-the-fly multiparty computation
on the cloud via multikey fully homomorphic encryption. In: Proceedings of the
Forty-Fourth Annual ACM Symposium on Theory of Computing, pp. 1219–1234.
ACM (2012)
12. Parno, B., Raykova, M., Vaikuntanathan, V.: How to delegate and verify in public:
verifiable computation from attribute-based encryption. In: Cramer, R. (ed.) TCC
2012. LNCS, vol. 7194, pp. 422–439. Springer, Heidelberg (2012)
13. Peter, A., Tews, E., Katzenbeisser, S.: Efficiently outsourcing multiparty compu-
tation under multiple keys. IEEE Trans. Inf. Forensics Secur. 8(12), 2046–2058
(2013)
14. Jakobsen, T.P., Nielsen, J.B., Orlandi, C.: A framework for outsourcing of secure
computation. In: ACM Cloud Computing Security Workshop (2014)
15. Sun, Y., Wen, Q., Zhang, Y., Zhang, H., Jin, Z., Li, W.: Two-cloud-servers-assisted
secure outsourcing multiparty computation. Scientific World J. 2014, 7 (2014)
16. Wang, B., Li, M., Chow, SSM., Li, H.: Computing encrypted cloud data efficiently
under multiple keys. In: IEEE Conference on Communications and Network Secu-
rity (CNS), pp. 504–513. IEEE (2013)
17. Yao, A.C.: Protocols for secure computations. In: SFCS 1982 23rd Annual Sym-
posium on Foundations of Computer Science, pp. 160–164, November 1982
Software and Mobile Security
Privacy-Enhanced Data Collection Scheme
for Smart-Metering
Jan Hajny(B), Petr Dzurenda, and Lukas Malina
Department of Telecommunications, Brno University of Technology, Technicka 12,
616 00 Brno, Czech Republic
{hajny,dzurenda,malina}@feec.vutbr.cz
http://crypto.utko.feec.vutbr.cz
Abstract. New types of devices, such as smart-meters, wearables and
home appliances, have been connected to the Internet recently. Data
they send is usually very privacy sensitive, containing personal infor-
mation about, e.g., household consumption, health status or behavior
profiles of family members. In this paper, we propose a cryptographic
scheme for the protection of data collection systems that is secure (in
the sense of data authenticity and integrity) and privacy-friendly at the
same time. This functionality is achieved by designing a novel group sig-
nature that provides signature anonymity, unlinkability and untraceabil-
ity while retaining features for malicious user identification. Besides the
full cryptographic specification, we also provide implementation results
that confirm the computational efficiency of the scheme allowing easy
deployment on existing devices.
Keywords: Data collection · Sensors · Smart-metering · Privacy ·
Attributes · IoT · Security · Cryptography
1 Introduction
There are many applications where secure data collection from remote devices
is important. The examples are temperature sensors, human activity and health
sensors, machine operation status sensors, home automation equipment or
implants in future. Although our scheme can be used in all these applications,
we’ll use the smart-metering as the example throughout the paper. The reason
for our choice is that smart-metering is becoming a significant topic world-wide
and a large-scale deployment of intelligent gas/water/electricity consumption
meters to households is expected in a very short time. The legislation, secu-
rity profiles and certification procedures are being finalized. The purpose of this
paper is to show that not only the security but also privacy protection is impor-
tant in data collection systems and that there are actually technical means for
achieving strong privacy protection in secure data collection systems.
The scheme presented in this paper is a specific version of a group signature.
It makes it possible that data originating from a smart-meter is digitally signed
c© Springer International Publishing Switzerland 2016
D. Lin et al. (Eds.): Inscrypt 2015, LNCS 9589, pp. 413–429, 2016.
DOI: 10.1007/978-3-319-38898-4 24
414 J. Hajny et al.
at the device so that it cannot be altered or manipulated during the transfer.
However, the signature only reveals that the data is originating from a group
of authorized meters, the concrete identification number (ID) of the meter is
not disclosed. To further improve privacy protection, all signatures of a single
meter are mutually unlinkable. If the owner wishes so, it cannot be distinguished,
whether the signed data is coming from a single smart-meter or different smart-
meters. That allows energy suppliers to have a statistical overview about the
consumption in a given area but prevents them from linking the consumption
profile to concrete users. If a user wishes so, e.g., if smart-meters are used not
only for statistical data collection but also for billing, the identity might be
disclosed by the smart-meter using standard methods.
In contrast to most existing schemes, the scheme proposed here contains
features for the practical revocation of invalid users and the identification of
malicious users. In case the collector needs to reveal the signer’s identity, he
may ask a special entity that is able to de-anonymize the group signature and
disclose the smart-meter’s ID to the collector. However, such an action must be
supported by reasonable evidence.
1.1 Model Scenario
Today’s smart-meters have the ability to upload measured data to central stor-
age. The data is used for statistical reasons, network planning, load balancing or
the identification of potential problems in distribution networks. Data needs to
be anonymized to preserve privacy of users. However, it is necessary to prevent
malicious users from flooding the central storage with false, misleading data. The
scheme presented in this paper provides mechanisms assuring that all messages
delivered to the central storage are authentic (originating from real, authorized
smart-meters) and integral (have not been tampered during transfer) without
disclosing the identity of users. Each smart-meter has its own private key that
is used to prove that it belongs to the group of authorized smart-meters. If the
owner’s identity needs to be disclosed (a serious problem is discovered from data
measured, messages are coming from stolen/malicious meters, etc.), it is still pos-
sible, however this feature is strongly protected against misuse by cryptographic
mechanisms and available only to certain authorities.
1.2 Related Work
In existing data collection schemes, privacy is usually protected by two main
mechanisms, i.e., pseudonyms and group signatures.
Privacy preserving solutions based on pseudonyms have been proposed, e.g.,
in [14,28,29]. Some schemes need additional pseudonimization infrastructure,
e.g. [29]. The work [28] uses anonymous certificates which are stored in a tamper-
proof device. This approach uses a set of temporal pseudonyms and fast changing
of these pseudonyms provides the privacy protection. Nevertheless, this approach
is burdened by the pre-loading and storing of a large number of anonymous
Privacy-Enhanced Data Collection Scheme for Smart-Metering 415
certificates with pseudonyms. For low-performance devices like smart-meters,
the management of pseudonyms becomes a too complex operation.
The second approach is based on general group signatures. They provide user
anonymity by producing message signatures on behalf of a group. Generally,
group signatures guarantee the anonymity of honest users and the traceability
of misbehaving users. A large number of group signatures has been proposed,
e.g., in [2,3,5,10,12,20,21]. In particular, the scheme called BBS [2] serves as a
fundamental building block for many security solutions (e.g., [23,31]). However
most schemes lack efficient revocation mechanisms that allow the removal and de-
anonymization of invalid users. Mechanisms for revocation have been proposed
for schemes based on bilinear pairings [4,24]. Nevertheless, these schemes need
several expensive operations, mostly bilinear pairings, modular exponentiations
and multiplications and are not appropriate for applications using computation-
ally very restricted devices such as smart-meters, wearables, wireless sensors,
etc. Currently, achieving reasonable privacy of honest users and the revocability
and de-anonymization of malicious users is an unresolved problem.
In addition to group signatures, the signatures based on anonymous creden-
tials [9,17,19,26] are also an option. However, these schemes are more focused
on privacy protection in access-control applications and lack features for efficient
revocation and identification of malicious users too [22].
Finally, some of the schemes analyzed [1,18] rely on the hardware tamper-
resistance. However, it is unrealistic to expect the presence of a tamper-proof
key storage when using sensors and wearables.
1.3 Our Contribution
In this paper, we propose a novel cryptographic data collection (DC) scheme
addressing the above identified weaknesses of existing systems. In particular,
our scheme is designed to provide the following features.
– Provable Security: our DC scheme is based on provably secure crypto-
graphic primitives, particularly the interactive proofs of knowledge about dis-
crete logarithms [30] in the Okamoto-Uchiyama (OU) group [25]. We provide
the full security analysis in Sect. 4.
– Privacy Protection Features: the DC scheme provides features for the
protection of users’ privacy and digital identity, namely the hiding of user IDs
and the unlinkability and untraceability of signatures.
– Revocation of Invalid Users: it is possible to efficiently revoke invalid users
without affecting remaining users.
– Identification of Malicious Users: using existing schemes, it is very diffi-
cult (if not impossible) to simultaneously provide privacy-enhancing features
(signatures anonymity, untraceability and unlinkabilty) and efficient identifi-
cation of malicious users. In our scheme, it is possible to obtain all these fea-
tures without negative effects on communication and computation efficiency.
– No Tamper-Proof Devices: the scheme has cryptographic protection
against collusion attacks. The user’s private signing key is stored only in
416 J. Hajny et al.
user’s device and cannot be used for collusion attacks even if extracted by
malicious users. That makes the implementation on available hardware lack-
ing the tamper-proof storage much easier.
– Computational and Communication Efficiency: our DC scheme is com-
putationally efficient enough to run on low-resource devices like smart-meters
and micro-controllers.
2 Scheme Description
In this section, we present the overview of our scheme and describe the entities
and cryptographic protocols.
2.1 Notation
For various proofs of knowledge or representation, we use the efficient notation
introduced by Camenisch and Stadler [7]. The protocol for proving the knowledge
of discrete logarithm of c with respect to g is denoted as PK{α : c = gα}. The
proof of discrete log equivalence with respect to different generators g1, g2 is
denoted as PK{α : c1 = gα1 ∧ c2 = gα2 }. A signature by a traditional signature
scheme (e.g., RSA) of a user U on some data is denoted as SigU (data). The
symbol “:” means “such that”, “|” means “divides”, “|x|” is the bitlength of x
and “x ∈R {0, 1}l” is a randomly chosen bitstring of maximum length l.
2.2 Scheme Overview
There are three types of entities in our scheme: Meter, Collector and Revocation
Authority.
– Meter (M): the Meter is the source of data. It acquires data from mea-
surement, signs it using it’s private key and sends it to the Collector. Meters
represent users in our scheme.
– Collector (C): is the destination where all data is collected. It receives data
from all Meters, verifies the group signatures and further processes them. The
Collector is assured that data is coming from a predefined group of Meters,
however the concrete IDs of the Meters remain hidden.
– Revocation Authority (RA): does the initial setup of the system including
system parameters generation and participates on the management of meters,
particularly on adding new Meters and removing invalid Meters from the
system. RA participates on the de-anonymization of malicious Meters. RA is
a semi-trusted authority as it can revoke Meters but is unable to de-anonymize
Meters by itself only.
The entities engage in the following protocols.
– (params,KRA,KC) ← Setup (k, l,m): is run by the Revocation Authority
and the Collector. It inputs security parameters (k, l,m) and outputs system
parameters params, RA’s private key KRA and Collector’s private key KC .
Privacy-Enhanced Data Collection Scheme for Smart-Metering 417
– KM ← getKey (params,KC ,KRA): is run by the Revocation Authority, the
Collector and the Meter. It inputs system parameters params, RA’s and C’s
private keys KRA and KC and outputs the private key of a new Meter KM .
KM is the Meter’s private output of the protocol, no other entity learns the
value of KM although they cooperate on its generation.
– GSKM (data) ← GroupSign (params, data,KM ): is run by the Meter. The
algorithm inputs system parameters params, data and Meter’s private key
KM and outputs the group signature GSKM (data).
– {0, 1} ← GroupVerify (params, data,GSKM (data)): is run by the Collector.
The algorithm inputs the system parameters params, data and Meter’s group
signature GSKM (data) and outputs 1 if the signature is valid and the Meter
has not been revoked.
– rev ← Revoke (params,GSKM (data),KRA): is run by the Collector and Revo-
cation Authority. In case Meter needs to be removed from the system or a sig-
nature must be de-anonymized due to some misbehavior, the Collector sends
the signature to Revocation Authority that revokes the Meter by putting its
key-derivate rev on a public blacklist. The signatures of blacklisted Meters
are always rejected by the Collectors.
– IDM ←Identify(params,GSKM (data),KRA,KC): is run by the Collec-
tor and Revocation Authority. The protocol inputs the system parameters
params, the group signature GSKM (data) and private keys KRA,KC and
outputs the Meter’s identifier IDM as C’s private output. Only C learns the
Meter’s ID but RA must cooperate on that disclosure.
The overview of the architecture of the scheme is depicted in Fig. 1.
Fig. 1. Architecture of DC scheme proposed.
418 J. Hajny et al.
2.3 Description of Cryptographic Protocols
We provide the full description of all cryptographic protocols, i.e., Setup, getKey,
GroupSign, GroupVerify, Revoke and Identify in this section.
Primitives Used. Two key cryptographic primitives are used in the scheme.
They are the commitment schemes and the non-interactive zero-knowledge proof
of knowledge protocols. Both primitives are used either in the DSA group modulo
large prime p [15], denoted as Z∗p, or in the Okamoto-Uchiyama group modulo
product n, where n = r2s, and r, s are large safe primes, denoted as Z∗n [25].
The scheme presented in this paper relies on the assumption that the discrete
logarithms are difficult to compute in Okamoto-Uchiyama (OU) group, similarly
as in groups modulo primes or RSA composites. However, if factorization (r, s)
of OU modulus n = r2s is known, the discrete logarithms can be efficiently
computed. For example, w from c = gw mod n can be computed as:
logg c = w =
((cr−1 mod r2) − 1)/r
((gr−1 mod r2) − 1)/r mod r.
The discrete logarithm can be computed only by entities who know the factor-
ization (r, s), as proven in [25].
Setup. (params,KRA,KC) ← Setup(k, l,m) - The Setup protocol is used to
generate all system parameters and private keys of C and RA. It inputs the
security parameters k (length of the output of the hash function used), l (length
of Meter’s private key) and m (protocol error parameter).
The Collector defines a group Z∗p by randomly choosing the prime modulus
p and elements h1, h2 of large order q : |q| = 2l and q|(p − 1).
The Revocation Authority defines a group Z∗n by randomly choosing the
modulus n : n = r2s and r, s are large safe primes such that r = 2r′ + 1 and s =
2s′ +1 holds and r′, s′ are also primes. RA selects a random element g1 of orders
ord(g1) = rr′ in Z∗r2 and ord(g1) = rr
′s′ in Z∗n. RA also randomly generates its
secrets S1, S2 : |S1| = 2.5l, |S2| = l and GCD(S1, φ(n)) = GCD(S2, φ(n)) = 1
and computes a value g2 = gS21 mod n.
For each group of meters, RA computes the group public key GPK =
gS11 mod n. For simplicity, we consider only one group in this paper, but many
group public keys can be defined analogically.
The values q, p, h1, h2, n, g1, g2, GPK are made public as system parameters
params. The values r, s, S1, S2 are securely stored at RA as the KRA key. C
generates a keypair of any conventional signature scheme (like RSA or DSA),
stores its private key as KC and publishes its public key.
getKey. KM ← getKey(params,KC ,KRA) - The getKey protocol is split into
two parts. The first one runs between the Meter and the Collector while the sec-
ond runs between the Meter and RA. The purpose of the protocol is to generate
a private key of the Meter KM in such a way that only the Meter learns the
value but both C and RA contribute to its creation.
Privacy-Enhanced Data Collection Scheme for Smart-Metering 419
RA Meter Collector
w′1 ∈R {0, 1}2l−1, w2 ∈R {0, 1}l−1
CC = commit(w
′
1, w2) = h
w′1
1 h
w2
2 mod p
PK{w′1, w2 : CC = hw
′
1
1 h
w2
2 }, SigM (CC)−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−→
Store (CC , SigM (CC))
SigC(CC)←−−−−−−−−−−−−−−−−−−−−−−−−−−
GPK′ = gw
′
1
1 g
w2
2 mod n
GPK′, CC , SigC(CC),
PK{(w′1, w2) : CC = hw
′
1
1 h
w2
2 ∧ GPK′ = gw
′
1
1 g
w2
2 }←−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Random generator: g3 ∈R Z∗n
w′′1 ∈R {0, 1}l
w3 : GPK = g
w′1
1 g
w′′1
1 g
w2
2 g
w3
3 mod n
Random primes: {w31, w32, . . . , w3(j−1) ∈R {0, 1}l}
w3j = w3(w31w32 . . . w3(j−1))
−1 mod φ(n)
w′′1 , (w31, w32, . . . , w3j), g3−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−→
Meter’s private group key: KM = {w1 = w′1 + w′′1 , w2, (w31, w32, . . . , w3j), g3}
GPK = gw11 g
w2
2 g
w31...w3j
3 mod n
Fig. 2. getKey protocol in CS notation.
In the first part, the Meter randomly generates its portion of the key (w′1, w2)
and commits to these values. It digitally signs its commitment CC using a con-
ventional signature scheme including owner’s real identity and sends it to the
Collector together with the proof of construction PK. The Collector checks the
proof, the signature and the identity of the Meter’s owner. If the Meter is autho-
rized to be included in the group, the Collector returns the commitment, this
time signed by his KC (again, any classical signature can be used, like RSA)
together with a unique, randomly generated identifier IDM . By this procedure,
the Collector certifies that the Meter belongs to the group of meters sharing
the GPK public group key. If more groups are available, the signature also con-
tains the information about the concrete group. The Collector stores the whole
protocol transcript in its database.
In the second part, the rest of the Meter’s key is issued. To have a valid private
key for group public key GPK, the Meter must have values (w1, w2, w3, g3) so
that
GPK ≡ gw11 gw22 gw33 mod n (1)
holds. The Meter creates another commitment GPK ′ to his keys (w′1, w2), this
time using the Okamoto-Uchiyama group Z∗n. The Meter sends both commit-
ments and Collector’s signature on the commitment to RA and proves that the
keys in commitments are the same. If the proof and signatures are valid, RA
420 J. Hajny et al.
chooses g3 (a random element with same properties as g1), random w′′1 (RA’s
contribution to Meter’s key so that w1 = w′1 + w
′′
1
1) and w3 such that the Eq. 1
holds. This can be done only by RA who knows the Okamoto-Uchiyama trapdoor
secret (the factorization of n) as w3 = logg3(GPK/(g
w′′1 GPK ′)).
The w3 is then split into j factors modφ(n) and sent back to the Meter as
RA’s portion of Meter’s private key. The Revocation Authority stores the whole
protocol transcript in its database.
As a result, the Meter knows a unique discrete logarithm representation
w1, w2, (w31 . . . w3j) of public GPK. The values w1, w2, (w31 . . . w3j), g3 are the
Meter’s private key corresponding to the group public key GPK.
The getKey protocol is fully specified and depicted in CS notation in Fig. 2.
GroupSign. GSKM (data) ← GroupSign(params, data,KM ) - The GroupSign
algorithm inputs system parameters params, Meter’s private key KM and mea-
sured data data and outputs a group signature GSKM (data). The signature
certifies that the Meter has a valid private key KM corresponding to the group
public key GPK but does not disclose any more information about the Meter,
including its identifier. The protocol is the non-interactive proof of knowledge
signature based on the Fiat-Shamir heuristic [13]. The Meter proves using a
zero-knowledge proof of knowledge protocol that it knows the discrete logarithm
representation of GPK, i.e., it knows the private key (w1, w2, w3). To provide
the anonymity and unlinkability of signatures, all unique values must be ran-
domized. Therefore, the unique g3 must be randomized to g′3 using half of the
key w3. With w3 split into 20 values, i.e. setting the parameter j to 20, we get
enough combination variants to randomize
(
20
10
)
= 184 756 signatures. Further-
more, we randomize each signature by using a unique per-signature key KS . To
provide revocation and identification features, commitments to keys (w1, w2,KS)
denoted as C12, C1S are included in the signature.
The GroupSign protocol is fully specified and depicted in CS notation in
Fig. 3.
GroupVerify. {0, 1} ← GroupVerify(params, data,GSKM (data)) - The group
signature verification is composed of the verification of the zero-knowledge proofs
and the revocation check. The verification of proofs of knowledge depends on con-
crete implementation, the signature check used in our implementation is shown
in Fig. 4. The revocation check is done by a single equation Crev12
?
≡ C1S (mod n)
where the commitments C12, C1S are checked against the revocation list. If the
equation holds for any of rev values present on the revocation list, the Meter has
been revoked and the signature is rejected. Otherwise, the signature is accepted.
Revoke. rev ← Revoke(params,GSKM (data),KRA,KC): the protocol inputs
the system parameters params, the signature GSKM (data), RA’s and C’s private
keys KRA,KC and outputs the revocation information rev. The rev value is then
put on a blacklist so that all signatures can be checked against the blacklist for
revoked users.
1 RA’s key contribution is necessary to prevent malicious users from submitting mal-
formed keys allowing attacks on RA’s secrets.
Privacy-Enhanced Data Collection Scheme for Smart-Metering 421
Fig. 3. GroupSign protocol in CS notation.
In the Okamoto-Uchiyama group, which is used in this scheme, it is generally
hard to compute discrete logarithms as it is in the RSA and DSA groups. But
there is a trapdoor value, the factor r of modulus n, which makes the discrete
logarithm computation possible. The only entity, that knows the factorization
of n, thus the value of r, is RA (Revocation Authority). From logg1 C12, the
RA gets KS(w1 + w2S2). From logg1 C1S , RA gets KS . Then, using r, RA is
able to compute the revocation information rev = (w1 + w2S2)−1 mod (rr′s′).
The rev value is put on a blacklist. Then, the equation Crev12
?≡ C1S (mod n) is
evaluated during all signature verifications for all revs. If it holds, the Meter has
been revoked and the Collector rejects the signature.
Identify. IDM ← Identify(params,GSKM (data),KRA,KC) - The purpose
of the protocol is to de-anonymize the signature so that the concrete Meter is
422 J. Hajny et al.
disclosed. This can be done only in exceptional situations, for example in cases
in which malicious users need to be identified. In that case the Collector sends to
the Revocation Authority the signature GSKM (data). RA gets KS(w1 + w2S2)
and KS in the same way as in the Revoke protocol above. Using these value,
RA is able to compute gw11 g
w2
2 = g
w1+w2S2
1 and find in its getKey transcript
database the corresponding commitment CC . The commitment is then sent back
to Collector, who can learn the Meter’s identifier IDM and owner’s identity from
CC using its getKey transcript database. Using this method, it is assured, that
Collector and Revocation Authority must cooperate on the de-anonymization
and only Collector learns the Meter’s and owner’s identity. This distribution
of privileges protects users’ privacy and makes the scheme less vulnerable to
attacks.
3 Scheme Implementation
In Sect. 2, we used the abstract CS notation to describe the protocols. This nota-
tion allows simple description of proofs of knowledge about discrete logarithms
according to their purpose. It has been shown in [8] that a large variety of proofs
and their logical compositions can be constructed. However, for implementation,
it is necessary to describe the protocols in details. The proof of knowledge proto-
cols can be implemented in many ways, interactive or non-interactive. We have
chosen the non-interactive implementation based on Fiat-Shamir heuristic [11]
and Schnorr signatures [30]. In our construction, the challenge e is computed as
a hash function of all past cryptographic values instead of receiving e from the
Collector. This construction has been proven secure in the random oracle model
[27]. The full specification of GroupSign and GroupVerify protocols is shown
in Fig. 4.
3.1 Performance Evaluation
The scheme proposed requires no complex operations, such as bilinear pairings.
Only simple modular operations are required. To compute a group signature, the
Meter must compute 11 modular exponentiations and 3 modular multiplications.
To verify a signature, the Collector must compute 12 modular exponentiations
and 10 modular multiplications plus one exponentiation per an item on a black-
list. These operations are easily computable on contemporary micro-controllers
in a very short time. We implemented the operations, i.e., modular exponenti-
ation (Mexp), modular multiplication (Mmul), plain multiplication (Mul) and
hash function (Hash), on a device with 900 MHz ARM Cortex-A7 CPU with
1 GB RAM using 6 different modular arithmetic libraries written in C. The per-
formance results of the fastest library, GMP [16], are shown in Fig. 5. The size of
the operands is shown in the graph captions and the size of modulus is 2048 b.
We present the average of 100 measurements.
The results show that the most computationally demanding operation in
the scheme takes around 57 ms using the fastest library (GMP [16]). We also
Privacy-Enhanced Data Collection Scheme for Smart-Metering 423
implemented other required operations (random number generation, (modular)
multiplication, hash functions, subtraction) but most of them were faster than
the modular exponentiation at least by several orders of magnitude.
The total time required to compute a group signature using our experimental
implementation was under 0.5 s and the time of verification on the same device
was also under 0.5 s. We consider these results to be a good proof of practical
implementability of our scheme on existing, off-the-shelf devices commonly used
in smart-metering applications.
4 Scheme Analysis
In this section, we show that the scheme proposed in this paper is secure and
privacy-friendly. We prove that group members are able to construct a valid
signature on data (the scheme is complete), that non-members are not able to
create a valid signature on data (the scheme is sound) and that the signature
leaks no unnecessary information about signers (the scheme is zero-knowledge).
4.1 Security Analysis
Completeness The group members who know a valid private group key KM =
(w1, w2, w3, g3) are always able to construct a signature that is accepted by the
Collector’s verification equations shown in Fig. 4. The completeness is proven by
Eqs. 2–8. All operations are in Z∗n.
Ā = AegzS11 g
zS2
2 g
′zS3
3 = GPK
eKSgrS11 g
−eKSw1
1 g
rS2
2 g
−eKSw2
2 g
′rS3
3 g
′−eKSw′′3
3 =
= grS11 g
rS2
2 g
′rS3
3 = Ā (2)
Ā = AeGPKzS = GPKeKSGPKrSGPK−eKS = GPKrS = Ā (3)
C̄12 = Ce12g
zS1
1 g
zS2
2 = g
w1KSe
1 g
w2KSe
2 g
rS1
1 g
−eKSw1
1 g
rS2
2 g
−eKSw2
2 = g
rS1
1 g
rS2
2 = C̄12
(4)
Ā
C̄12
=
A
C12
e
g′zS33 = (
gw1KS1 g
w2KS
2 g
′w′′3 KS
3
gw1KS1 g
w2KS
2
)eg′rS33 g
′−eKSw′′3
3 = g
′rS3
3 =
=
grS11 g
rS2
2 g
′rS3
3
grS11 g
rS2
2
=
Ā
C̄12
(5)
¯div =
A
C12
e
Cz3S = (
gw1KS1 g
w2KS
2 g
′w′′3 KS
3
gw1KS1 g
w2KS
2
)eCr3S C
−ew′′3
S = C
r3
S = ¯div (6)
C̄S = CeSg
′zS
3 = g
′eKS
3 g
′rS
3 g
′−eKS
3 = g
′rS
3 = C̄S (7)
C̄1S = Ce1S(g1)
zS = geKS1 g
rS
1 g
−eKS
1 = g
rS
1 = C̄1S (8)
424 J. Hajny et al.
Fig. 4. GroupSign and GroupVerify algorithms implementation.
Privacy-Enhanced Data Collection Scheme for Smart-Metering 425
Fig. 5. Time necessary to compute modular operations on 900MHz ARM microproces-
sor using GMP library.
Soundness. We implemented the group signature using the Fiat-Shamir heuris-
tic applied to discrete logarithm proof of knowledge protocols. This is a common
construction used in many other schemes [7]. Here, we follow the proof presented
in [6,18].
In the detailed description of the GroupSign protocol provided in Fig. 4 it
is visible that the Meter first generates randomness (values rS1, rS2, rS3, rS , r3),
then computes the commitments to these values (values Ā, Ā, C̄12, C̄S , C̄1S , ¯div).
The hash of all these values is then used as a challenge e. Since the hash is a one-
way function, the Meter is unable to predict e before selecting the randomness.
Thus, after committing to randomness, the Meter must be ready to response
any challenge e since its value is unpredictable.
In the proof below we show that Meters that are ready to respond at least
2 challenges (e, e′) know the private group key KM . Thus, malicious users not
aware of KM are able to answer at most 1 challenge of 2k possible challenges,
thus have the probability P = 1
2k
of creating a valid signature.
Let’s assume that exists a malicious Meter that is able to produce signatures
for different challenges (e, e′) that get accepted by the Collector, without knowing
KM . A valid signature must pass all signature checks shown in Fig. 4. Thus, both
the equations must hold:
C̄1S = Ce1S(g1)
zS (9)
C̄1S = Ce
′
1S(g1)
z′S (10)
By rewriting the equations we get:
1 = Ce−e
′
1S g
zS−z′S
1 (11)
426 J. Hajny et al.
And finally we get:
logg1 C1S = (zS − z′S)(e′ − e)−1 (12)
The Eq. 12 can be easily computed by the Meter since it knows all values
e′, e, zS , z′S . Thus, the Meter knows the logg1 C1S . Therefore, it knows KS .
The same method can be applied to all verification equations, proving that
Meter must know KS ,KSw1,KSw2,KSw′′3 to be able to construct a valid signa-
ture.
However, from these values, the discrete logarithm representation of GPK,
thus KM , can be efficiently computed. We reached the contradiction to our
assumption, there are no users that can pass the verification checks without
knowing KM .
Zero-Knowledge. The protocols specified in Sect. 2 can be implemented in
an interactive version with a challenge e randomly chosen by the Collector. In
that case, the honest-verifier zero-knowledge (HVZK) property can be proven
by constructing the standard HVZK simulator. The simulator is able to out-
put a protocol transcript that is computationally indistinguishable from a real
protocol without using any Meter’s secrets. Thus, it can be proven that the pro-
tocol leaks no secret information. The simulator proceeds in a standard way, i.e.
first randomly selecting the answers z, randomly generating the challenge e and
computing the commitments using the Collector’s verification equations.
However, we use the non-interactive version based on hash function in our
implementation. The random challenge is substituted by a hash output to
improve the performance of the scheme. Nevertheless, we disclose exactly the
same values as in the interactive version except the hash. Therefore, assum-
ing the hash function is secure, the protocol releases no information about the
private keys.
4.2 Privacy Analysis
In the beginning of the paper we stated that the group signature is anonymous,
untraceable and unlinkable to other signatures of the same Meter. We analyze
these properties below.
– Anonymity: the only link between a particular Meter and a signature is the
private key KM . However, the key is never disclosed in any form as proven
in the zero-knowledge analysis above. The g3 value is randomized to g′3 =
g
w′3
3 mod n for each signature.
– Untraceability: the Collector is unable to link the getKey protocol tran-
script and the GroupVerify protocol transcript. This is achieved by using
different modular groups in both protocols. During the getKey protocol, the
Collector learns the Meter’s key commitment in Z∗p. During the GroupVerify
protocol, the Collector learns the Meter’s key commitment in the Z∗n group.
It is computationally unfeasible to decide whether same keys are present in
Privacy-Enhanced Data Collection Scheme for Smart-Metering 427
commitments using different groups unless discrete logarithm is computable.
In both groups the computation of discrete logarithms is hard without the
knowledge of a trapdoor.
– Unlinkability: no entity except Revocation Authority is able distinguish
whether two signatures originate from a single Meter or two different Meters.
This holds even if same data was signed. This feature was achieved by the
randomization of all Meter-specific values by the session key KS . As visible
in Fig. 4, all values that would be otherwise constant are randomized by KS .
The KS key changes for each signature. The de-randomization is possible only
if discrete logarithms can be efficiently computed. The only entity that can
compute discrete logarithms in Z∗n is RA because it knows the factorization
of n thus knows the Okamoto-Uchiyama trapdoor. This RA’s ability is used
to achieve the revocation and malicious user identification features.
5 Conclusion
In this paper, we introduced a novel scheme for secure and privacy-friendly
data collection. The scheme assures data group authenticity and integrity, like
the classical digital signatures. In addition, the privacy-enhancing features are
added. The sender’s identity is not disclosed to collectors and all signatures are
mutually unlinkable and untraceable. In contrast to existing schemes, our scheme
provides advanced features for the identification and revocation of malicious
users. The attackers can be efficiently revoked from the system and their identity
can be disclosed so that they are held responsible for their acting in the system.
Additionally to the full cryptographic specification and security analysis, we also
presented the performance analysis. The implementation results show that the
scheme including revocation features is practical and easily implementable on
microprocessors commonly used in existing smart-metering systems. Currently,
the scheme is being piloted in smart-house applications in cooperation with
industrial partners.
Acknowledgments. Research described in this paper was financed by the National
Sustainability Program under grant LO1401, the Czech Science Foundation under
grant no. 14-25298P “Research into cryptographic primitives for secure authentica-
tion and digital identity protection” and by Technology Agency of the Czech Republic
project TA04010476 “Secure Systems for Electronic Services User Verification”. For
the research, infrastructure of the SIX Center was used.
References
1. Alpar, G., Hoepman, J.H., Lueks, W.: An attack against fixed value discrete log-
arithm representations. Cryptology ePrint Archive, Report 2013/120 (2013)
2. Boneh, D., Boyen, X., Shacham, H.: Short group signatures. In: Franklin, M. (ed.)
CRYPTO 2004. LNCS, vol. 3152, pp. 41–55. Springer, Heidelberg (2004)
428 J. Hajny et al.
3. Boneh, D., Shacham, H.: Group signatures with verifier-local revocation. In: Pro-
ceedings of the 11th ACM Conference on Computer and Communications Security,
CCS 2004, pp. 168–177. ACM, New York, NY, USA (2004)
4. Camenisch, J., Kohlweiss, M., Soriente, C.: An accumulator based on bilinear maps
and efficient revocation for anonymous credentials. In: Proceedings of the 12th
International Conference on Practice and Theory in Public Key Cryptography,
PKC 2009, pp. 481–500. Irvine, Springer, Berlin, Heidelberg (2009)
5. Camenisch, J.L., Lysyanskaya, A.: A signature scheme with efficient protocols. In:
Cimato, S., Galdi, C., Persiano, G. (eds.) SCN 2002. LNCS, vol. 2576, pp. 268–289.
Springer, Berlin, Heidelberg (2003)
6. Camenisch, J.L., Shoup, V.: Practical verifiable encryption and decryption of dis-
crete logarithms. In: Boneh, D. (ed.) CRYPTO 2003. LNCS, vol. 2729, pp. 126–144.
Springer, Berlin, Heidelberg (2003)
7. Camenisch, J.L., Stadler, M.A.: Efficient group signature schemes for large groups.
In: Kaliski Jr., B.S. (ed.) CRYPTO 1997. LNCS, vol. 1294, pp. 410–424. Springer,
Berlin, Heidelberg (1997)
8. Camenisch, J., Stadler, M.: Proof systems for general statements about discrete
logarithms. Technical report (1997)
9. Camenisch, J., Van Herreweghen, E.: Design and implementation of the idemix
anonymous credential system. In: Proceedings of the 9th ACM Conference on Com-
puter and Communications Security, CCS 2002, pp. 21–30. ACM, New York, NY,
USA (2002)
10. Delerablée, C., Pointcheval, D.: Dynamic fully anonymous short group signatures.
In: Nguyen, P.Q. (ed.) Progress in Cryptology-VIETCRYPT 2006. LNCS, vol.
4341, pp. 193–210. Springer, Heidelberg (2006)
11. Feige, U., Shamir, A.: Witness indistinguishable and witness hiding protocols. In:
Proceedings of the Twenty-Second Annual ACM Symposium on Theory of Com-
puting, STOC 1990, pp. 416–426. ACM, New York, NY, USA (1990). http://doi.
acm.org/10.1145/100216.100272
12. Ferrara, A.L., Green, M., Hohenberger, S., Pedersen, M.Ø.: Practical short
signature batch verification. In: Fischlin, M. (ed.) CT-RSA 2009. LNCS, vol. 5473,
pp. 309–324. Springer, Heidelberg (2009)
13. Fiat, A., Shamir, A.: How to prove yourself: practical solutions to identification
and signature problems. In: Odlyzko, A.M. (ed.) CRYPTO 1986. LNCS, vol. 263,
pp. 186–194. Springer, Berlin, Heidelberg (1987)
14. Finster, S., Baumgart, I.: Pseudonymous smart metering without a trusted third
party. In: 2013 12th IEEE International Conference on Trust, Security and Privacy
in Computing and Communications (TrustCom), pp. 1723–1728, July 2013
15. Gallagher, P., Kerry, C.: FIPS PUB 186-4: Digital signature standard (DSS) (2013).
http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf
16. GMP: The GNU multiple precision arithmetic library (2015). https://gmplib.org
17. Hajny, J., Dzurenda, P., Malina, L.: Privacy-PAC: privacy-enhanced physical access
control. In: Proceedings of the 13th Workshop on Privacy in the Electronic Society,
WPES 2014, pp. 93–96. ACM, New York, NY, USA (2014). http://doi.acm.org/
10.1145/2665943.2665969
18. Hajny, J., Malina, L.: Unlinkable attribute-based credentials with practical
revocation on smart-cards. In: Mangard, S. (ed.) CARDIS 2012. LNCS, vol. 7771,
pp. 62–76. Springer, Berlin, Heidelberg (2013)
19. Hajny, J., Malina, L., Tethal, O.: Privacy-friendly access control based on personal
attributes. In: Yoshida, M., Mouri, K. (eds.) IWSEC 2014. LNCS, vol. 8639, pp.
1–16. Springer, Heidelberg (2014). http://dx.doi.org/10.1007/978-3-319-09843-2 1
Privacy-Enhanced Data Collection Scheme for Smart-Metering 429
20. Hwang, J.Y., Lee, S., Chung, B.H., Cho, H.S., Nyang, D.: Short group signatures
with controllable linkability. In: 2011 Workshop on Lightweight Security & Privacy:
Devices, Protocols and Applications (LightSec), pp. 44–52. IEEE (2011)
21. Kim, K., Yie, I., Lim, S., Nyang, D.: Batch verification and finding invalid signa-
tures in a group signature scheme. IJ Netw. Secur. 13(2), 61–70 (2011)
22. Lapon, J., Kohlweiss, M., De Decker, B., Naessens, V.: Analysis of revocation
strategies for anonymous idemix credentials. In: De Decker, B., Lapon, J., Naessens,
V., Uhl, A. (eds.) CMS 2011. LNCS, vol. 7025, pp. 3–17. Springer, Berlin,
Heidelberg (2011). http://dx.doi.org/10.1007/978-3-642-24712-5 1
23. Lin, X., Sun, X., Ho, P.H., Shen, X.: GSIS: a secure and privacy preserving protocol
for vehicular communications. IEEE Trans. Veh. Technol. 56, 3442–3456 (2007)
24. Nguyen, L.: Accumulators from bilinear pairings and applications. In: Menezes, A.
(ed.) CT-RSA 2005. LNCS, vol. 3376, pp. 275–292. Springer, Berlin, Heidelberg
(2005)
25. Okamoto, T., Uchiyama, S.: A new public-key cryptosystem as secure as factoring.
In: Nyberg, K. (ed.) EUROCRYPT 1998. LNCS, vol. 1403, pp. 308–318. Springer,
Berlin, Heidelberg (1998)
26. Paquin, C.: U-prove cryptographic specification v1.1. Technical report, Microsoft
Corporation (2011)
27. Pointcheval, D., Stern, J.: Security proofs for signature schemes. In: Maurer,
U.M. (ed.) EUROCRYPT 1996. LNCS, vol. 1070, pp. 387–398. Springer, Berlin,
Heidelberg (1996). http://dx.doi.org/10.1007/3-540-68339-9 33
28. Raya, M., Hubaux, J.P.: Securing vehicular ad hoc networks. J. Comput. Secur.
15, 39–68 (2007)
29. Rottondi, C., Mauri, G., Verticale, G.: A protocol for metering data pseudonymiza-
tion in smart grids. Trans. Emerg. Telecommun. Technol. 26(5), 876–892 (2015).
doi:10.1002/ett.2760
30. Schnorr, C.P.: Efficient signature generation by smart cards. J. Cryptol. 4, 161–174
(1991)
31. Zhang, C., Lu, R., Lin, X., Ho, P.H., Shen, X.: An efficient identity-based batch
verification scheme for vehicular sensor networks. In: INFOCOM, pp. 246–250.
IEEE (2008)
A Secure Architecture for Operating
System-Level Virtualization on Mobile Devices
Manuel Huber(B), Julian Horsch, Michael Velten, Michael Weiss,
and Sascha Wessel
Fraunhofer AISEC, Garching Near Munich, Germany
{manuel.huber,julian.horsch,michael.velten,michael.weiss,
sascha.wessel}@aisec.fraunhofer.de
Abstract. In this paper, we present a novel secure architecture for
OS-level virtualization on mobile devices. OS-level virtualization allows
to simultaneously operate multiple userland OS instances on one physi-
cal device. Compared to previous approaches, our main objective is the
confidentiality of sensitive user data stored on the device. We isolate
the OS instances by restricting them to a set of minimal, controlled
functionality and allow communication between components exclusively
through well-defined channels. With our secure architecture, we there-
fore go beyond the common deployment of Linux kernel mechanisms,
such as namespaces or cgroups. We develop a specially tailored, stacked
LSM concept using SELinux and a custom LSM, leverage Linux capa-
bilities and the cgroups devices subsystem. Based on the architecture,
we present secure device virtualization concepts allowing to dynamically
assign device functionalities to different OS instances. Furthermore, we
develop a mechanism for secure switching between the instances. We
realize the architecture with a fully functional and performant implemen-
tation on the Samsung Galaxy S4 and Nexus 5 mobile devices, running
Android 4.4.4 and 5.1.1, respectively. With a systematic security evalu-
ation, we demonstrate that the secure isolation of OS instances provides
confidentiality even when large parts of the system are compromised.
Keywords: Mobile device security · Security architecture · Data confi-
dentiality · Operating System security
1 Introduction
Today’s mobile devices are not only widely used, but also represent a fingerprint
of their users. Essential corporate and private data is likely to be found on those
devices, rising the necessity to carefully consider security aspects, such as data
confidentiality protection. However, the prevalence of only few Operating System
(OSs), and the pace of their development make them prone to get targeted by
attackers [5,15]. The abundance of security issues makes these devices vulnerable
to a large number of attacks [16,22,23,31]. Efforts were made to mitigate the
susceptibility towards common attack vectors [1,3,10,14,21]. Nevertheless, an
c© Springer International Publishing Switzerland 2016
D. Lin et al. (Eds.): Inscrypt 2015, LNCS 9589, pp. 430–450, 2016.
DOI: 10.1007/978-3-319-38898-4 25
A Secure Architecture 431
adversary remains able to access all data on the phone with common privilege
escalation attacks. None of the approaches features an overall secure architec-
ture for data confidentiality, although being the utmost goal when it comes to
protecting sensitive private and corporate data.
A promising way to approach data confidentiality is to provide multiple, vir-
tualized environments on a single mobile device [6]. OS-level virtualization [19]
allows to simultaneously operate multiple userland OS instances running on a
single kernel instance. These virtualized instances are henceforth called contain-
ers. In [27,28], Wessel et al.propose such an architecture based on Android. How-
ever, their and other OS-level virtualization approaches [2,9] lack a full-fledged
secure architecture for domain isolation and data confidentiality protection.
In this paper, we present a novel secure architecture for OS-level virtualiza-
tion on mobile devices for Linux driven OSs. Our main objective is the confi-
dentiality of sensitive user data at container boundaries. This means, we achieve
data confidentiality when data inside a container remains confidential to other,
possibly malicious containers at all time. For this purpose, we isolate contain-
ers by restricting them to a set of minimal, controlled functionality. We confine
communication between components to only specific channels in our architecture.
Based on this, we develop secure device virtualization concepts and a convenient
mechanism for secure switching between containers. Addressing common OS-
level virtualization security requirements [24], we focus on the development of
an easily portable solution, suitable for real-life application. In particular, our
contributions are:
– The development of a kernel-based secure virtualization architecture for
data confidentiality, including a Secure Element (SE).
– Improved container isolation through confining containers to minimal, con-
trolled functionality and to only specific communication channels. We develop
a stacked Linux Security Modules (LSM) concept using Security-Enhanced
Linux (SELinux) and a custom LSM. We leverage Linux capabilities and the
control groups (cgroups) devices subsystem.
– A secure device virtualization mechanism allowing to dynamically assign
hardware functionalities on a per-container basis. A classification of devices
into different device categories.
– The introduction of a fast and secure container switch mechanism with
security devices.
– A full implementation on the Samsung Galaxy S4 and the Nexus 5 devices.
– A performance evaluation for the realization on the Nexus 5 device.
– A systematic security evaluation of our architecture showing data confi-
dentiality even when large parts of the system are compromised.
The paper is structured as follows. In Sect. 2, we present related work. We
describe our secure architecture in Sect. 3. In Sect. 4 we present our concept
for container isolation. Based on that, we elaborate the refined secure device
virtualization mechanisms in Sect. 5. We develop the secure container switching
mechanism in Sect. 6. In Sect. 7, we conduct a systematic security evaluation.
We describe the implementation and show performance results in Sect. 8 and
conclude in Sect. 9.
432 M. Huber et al.
2 Related Work
The necessity for data confidentiality protection results from the numerous
attacks on mobile device OSs, especially on the widespread Android platform
[16,22,23,31]. Another threat for confidentiality are applications that leak sensi-
tive data [13]. Approaches for security enhancements on Android are presented
in [1,3,10,14,21]. These approaches focus on the middleware layer to, e.g., gain
fine-grained control over the OS permission system [3,21], to restrict applications
from OS resources [10,14], or to harden the OS [1]. Introducing security mech-
anisms on middleware level results in a highly complex system, a large Trusted
Computing Base (TCB) and a very OS specific solution.
To tackle this problem, virtualization techniques create isolated environments
for distinct purposes, namely user level isolation, system- and OS-level virtualiza-
tion. User-level isolation [7,8,26] is an approach to create separate environments
through isolating applications on the framework level. A successful attack on
privileged processes results in gaining full control over the system. System vir-
tualization [11,17,25] deals with full OS virtualization including the kernel. The
approach is strongly hardware dependent, because drivers have to be reimple-
mented for all hardware devices. OS-level virtualization separates userland OS
instances running on a single modified kernel. An attacker must compromise the
kernel to break out of a container. Achieved with LXC, Jails [18], Docker [20],
OpenVZ, or Linux-VServer, the technique is established on x86 and considered
efficient [24,30].
Cells [2] is an OS-level virtualization approach for Android mobile devices.
They introduce device namespaces to provide a framework for device driver vir-
tualization on kernel-level. Device namespaces multiplex hardware driver states
on a per-container basis. With the concept of active device namespaces, drivers
are made aware of the current active namespace, i.e., the foreground container.
The work puts the main focus on realizing the functionality, but lacks the con-
sideration of security aspects. No secure architecture is provided and data con-
fidentiality is not discussed.
Based on Cells, Condroid [9] puts the focus on efficiency. Device virtualiza-
tion is mostly applied in the Android framework. More OS resources are shared
among the containers, such as their read only parts and OS services. For con-
tainer management, the authors port LXC and run it in a single host Android in
the root namespace. This makes the solution highly specific to a certain OS ver-
sion and blends domain isolation with domain interaction, resulting in a weaker
security model and a larger TCB.
AirBag [29] leverages OS-level virtualization in a single phone usage model for
probing and profiling of untrusted applications. The framework allows the user
to install and execute new applications quarantined inside a second, untrusted
container. In contrast to our approach, their objective is the preliminary analysis
of Android applications before their execution in the trusted container.
The virtualization approach by Wessel et al. [27,28] forms the starting point
of our work. They leverage mechanisms, like (device) namespaces and cgroups.
Focusing on security aspects and integrity protection, they develop a security
A Secure Architecture 433
Fig. 1. The secure virtualization architecture.
infrastructure. The infrastructure provides concepts for remote management,
secure communication and storage protection. In [27], the authors elaborate the
integration of an SE and a device provisioning and enrollment process with a cer-
tificate infrastructure. They describe a many-to-many usage model for contain-
ers, users and devices. However, their infrastructure lacks a secure architecture
for data confidentiality, secure device virtualization and container switching.
3 Architecture Overview
Figure 1 gives an overview on the components of our secure architecture. The
illustration depicts different containers C0, C1, ..., Cn running on a single Linux
kernel. We differentiate between components located in user and in kernel space.
Another differentiation is between common components on a stock Linux based
mobile device and between components we added. The latter ones are highlighted
by bold letters. The varying background grayscale colors visualize the separation
of components into different privilege levels. The dark gray colored components
are in the TCB in root namespace. The mid gray C0 is a privileged container in
contrast to the unprivileged containers Ci (i.e., C1, ..., Cn).
3.1 Hardware and Kernel Components
The hardware part consists of common hardware devices and security devices.
We define the SE, LED and power button as security devices. These are non-
virtualized hardware devices, because they serve a security critical purpose. They
are not accessible to C0..n. The LED and power button are usually available on
common mobile devices. In our architecture, the power button’s purpose is to
securely initiate a switch between containers (see Sect. 6). The LED is a secure
434 M. Huber et al.
container indicator for the user, showing the unique color of the currently active
container. C0..n are thus unable to disguise their identities to fake another con-
tainer. We use the SE as secure storage for integrity and confidentiality protec-
tion. The SE is a passphrase-protected device, e.g., a smartcard connected via
Near Field Communication (NFC). We securely virtualize the remaining devices
in order to ensure a seamless user experience and the operability of the contain-
ers on the device (see Sect. 5). That includes, amongst others, graphics, input,
Radio Interface Layer (RIL), sensors, or Wi-Fi device virtualization. In kernel
space, we substitute the stock mobile device’s kernel with our modified Linux
kernel. The kernel handles multiple containers through the (device) namespaces
feature. Further kernel mechanisms for container isolation and resource control
we leverage in our secure architecture are capabilities, cgroups, as well as a
stacked LSM with SELinux and a custom LSM.
3.2 User Space Components
Containers C0..n, the Container Management (CM) and Security Management
(SM) are located in user space. Only the SM and the CM are part of the TCB.
Security Management. The SM has the responsibility to securely and exclu-
sively communicate with different SEs. The SM performs cryptographic opera-
tions for the CM, such as container storage key unwrapping using the SE.
Container Management. The CM configures the kernel features and acts as
mediator between the containers. It has exclusive access to the LED and power
button. The CM is responsible of container operations, such as to start C0..n or
to securely switch between containers (see Sect. 6). The CM is also responsible of
container storage encryption. Container storage is protected with a symmetric
container key. This key is wrapped with the public key belonging to the SE’s
private key. When a container starts, the CM asks the SM with a provided
passphrase to unwrap the container key using the SE.
Container C0. This is a special, privileged container, comparable to dom0 in
XEN [4]. C0 is used for local container management with a Trusted GUI and
for secure device virtualization (see Sect. 5). The Trusted GUI enables the user
to securely enter the passphrase required for starting containers, to initiate a
container switch and to make container specific and device global settings. We
use the Driver MUXs as device multiplexers for user space device virtualization
over container boundaries. Device drivers, often proprietary binaries, are mostly
running only within a userland OS, such as Android. We therefore require C0 to
run a minimal OS for hardware device driver access.
Container Ci. These components are the isolated and unprivileged contain-
ers. The CM encapsulates C0..n into their specific namespaces, maintained by
the kernel. During start-up of a container, the CM creates the namespaces and
configures the security mechanisms. The vService in each container realizes an
interface to the CM for sending commands to a container, e.g., to shutdown,
suspend or resume. The Driver Proxies request device functionality from C0’s
A Secure Architecture 435
Fig. 2. Kernel mechanisms for container isolation.
Driver MUXs (see Sect. 5). This enables Ci to obtain specific device functional-
ities without explicit device access.
4 Container Isolation
In the following, we describe the isolation of the containers from each other and
the root namespace. In order to achieve strict isolation, we restrict C0..n to a
minimal set of functionality. We allow communication only over well-defined and
protected communication channels. Figure 2 depicts a detailed view on the con-
tainer isolation of Ci and Cj with the kernel mechanisms we make use of. We
isolate components on intra- and inter-container basis. We support and enforce
the commonly deployed LSM realization SELinux inside containers. This iso-
lates processes inside containers to protect it from being compromised. The CM
loads and enforces a global LSM policy for each container. We also require LSM
mechanisms for inter-container isolation. Therefore, we use the LSM stacking
mechanism1. This mechanism allows to register multiple LSMs in the kernel.
Multiple handlers are hence called on an LSM hook to perform access control.
A hook is successfully passed only if each of the handlers grants access to the
kernel resource.
4.1 Communication Channels
We specify secure and exclusive communication channels between the compo-
nents over well-defined interfaces. This restricts the components to interfaces
exclusively used for container management and for secure device virtualization.
First, we classify communication channels into three different layers of commu-
nication, as depicted in Fig. 3.
Layer 1 Communication. Layer 1 communication is on system call level, i.e.,
calls like open, write or ioctl, which are executed in the kernel. Any commu-
nication between components results in layer 1 communication interacting with
1 http://article.gmane.org/gmane.linux.kernel.lsm/22729.
436 M. Huber et al.
the kernel. On this layer, we prevent containers from unspecified device access
with the cgroups devices subsystem based on device major minor numbers. We
allow C0..n to directly access device drivers virtualized on kernel-level via device
namespaces (see Sect. 5). To prevent components from critical system calls, we
use Linux capabilities and our LSMs.
Layer 2 Communication. Layer 2 communication involves the communica-
tion between two or more processes. This layer represents all types of low-level
Inter-Process Communication (IPC) over OS resources, e.g., sockets, and results
in system calls. We separate this layer between containers through namespaces
isolation. With our custom LSM, we selectively allow access to defined kernel
resources relevant for IPC. An example is the denial of accessing certain sock-
ets. This makes it possible to explicitly grant or refuse the establishment of
communication channels.
Fig. 3. Communication channels of the secure architecture.
Layer 3 Communication. This layer uses a protocol for IPC between the
components. We secure the communication by message filtering and by utilizing
a secure protocol. Figure 3 illustrates the following layer 3 channels we allow.
– CM and SM: The CM uses this channel in the root namespace to retrieve
the results of the cryptographic operations that the SM executes.
– CM and external components: For remote device management via a back-
end, the CM offers a protocol on an update and remote control interface.
– CM and vService: To send commands to C0..n and to check their status,
the CM communicates via the status interface with the vService inside C0..n.
– CM and Trusted GUI: The CM offers a control interface for local container
management. The Trusted GUI in C0 uses this control interface.
– CM and Driver MUX: The Driver MUX utilizes this channel to notify
the CM via the vDeviceRegister interface of the user space virtualized device
functionality the multiplexer offers.
– CM and Driver Proxy: The Driver Proxy uses this channel to demand the
CM via the vDevice interface for setting up the connection channel to the
Driver MUX to obtain functionality of user space virtualized devices.
A Secure Architecture 437
– Driver MUX and Driver Proxy: This channel, set up by the CM, exists
for user space-based device virtualization. C0 accesses hardware devices on
layer 1 on behalf of Ci and selectively provides the functionality to Ci.
4.2 Identification and Isolation of OS Functionalities
To enforce data confidentiality across container boundaries, we prevent C0..n
from defying namespace boundaries through other than the specified channels.
In order to do so, we confine the containers to minimal OS functionalities with
the kernel mechanisms (see Fig. 2). System calls represent the interface via which
all components act and are thus crucial for our secure architecture. In order to
achieve a global view on these resources, we investigate all system calls and their
usage. Based on the whole set of system calls, we try to identify and group OS
functionalities. In the following, we elaborate the protection of the functionalities
using the aforementioned security mechanisms.
Mounting. We only allow containers to execute noncritical mount operations.
First, we embed every container into its own mount namespace, which pro-
vides each container with isolated filesystem mount views. For managing the
mount permissions of containers, we then introduce mount restrictions with our
custom LSM. This prohibits mounting of non-required resources and specifies
paths where a container can mount to. For example, C0..n are only allowed to
mount sysfs to /sys and procfs to /proc. Containers are, e.g., not allowed to
mount cgroups, which prevents C0..n from overwriting cgroups configurations.
Our custom LSM performs the mount permission checks based on a static mount
whitelist in our LSM policy. The list specifies the device, mount point, filesys-
tem type and mount flags. We furthermore drop the capability CAP SYS ADMIN,
because it comprises various critical functionality we prohibit. However, the
mounting privileges are part of this capability. We therefore introduce a new
capability CAP SYS MOUNT, which only allows a process to (un)mount and to cre-
ate new mount namespaces. The new capability contains the minimal required
subset of mount-related privileges former part of CAP SYS ADMIN.
Filesystem Access. For some of its mounted filesystems, a container should
only have limited file access. To achieve this, we define protection rules with our
custom LSM. We may assume fixed locations of objects in the filesystem due to
the fixed mount points we defined. We utilize path-based whitelists, to specify
the access permissions for filesystem locations. We define read-write, read-only
and privileged container whitelists in our LSM policy. The LSM traverses the
whitelists when the system triggers the corresponding LSM hooks, e.g., for the
open or ioctl system call. An example is the access restriction to the sysfs
filesystem. We allow a container to mount it in order to operate correctly, but
we limit the access in this filesystem. For example, the LSM restricts an attempt
from C0..n to set the LED color via the sysfs filesystem.
Device Access. Containers must be able to fulfill their usage purpose, which
often requires virtualized device functionality from C0, such as telephony or
438 M. Huber et al.